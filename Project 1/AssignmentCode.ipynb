{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac797774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create representative sampling -> proportional to each month\n",
    "# TODO: Visualize weekly each \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-color",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "## Exploratory data analysis and preprocessing\n",
    "\n",
    "The **exploratory data analysis** is the statistical treatment to which the samples collected during a research process in any scientific field are subjected.\n",
    "For greater speed and accuracy, the entire process is usually carried out by computer, with specific applications for statistical treatment.\n",
    "\n",
    "### Application to Data Mining\n",
    "\n",
    "In **data mining**, although not mandatory, it is a good practice to analyze the data you will be working with in order to observe its main characteristics in order to get an idea of the structure of the data set, and identify the target variable and possible modeling techniques.\n",
    "\n",
    "**Basic Process**\n",
    "- *Transform the data*: It helps us know what to do with null, missing values, or atypical data. In addition, it establishes if there is a need to reduce the dimensionality of data.\n",
    "- *Visualize*: Use some tool to make a graphical representation of the data, for example, R, Jupyter notebook, Google Colab, etc.\n",
    "- *Analyze and interpret*: Analyze and interpret the data through different visualizations.\n",
    "- *Document*: Document all the graphs and statistics generated.\n",
    "\n",
    "This process is also helpful when reviewing the data description to understand the meaning of each characteristic.\n",
    "\n",
    "There are several activities in doing an exploratory data analysis but in terms of data mining the key points to be made are:\n",
    "\n",
    "- Description of the data structure.\n",
    "- Identification of missing data.\n",
    "- Detection of outliers.\n",
    "- Identification of relationships between variable pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-africa",
   "metadata": {},
   "source": [
    "The **goal of this project** is to learn how to do data exploration. In this case, data from **New York City Yellow Taxis** is used.\n",
    "\n",
    "At the end of the notebook, you should be able to answer the following question:\n",
    "\n",
    "\n",
    "## How has covid affected the use of taxis in New York?\n",
    "\n",
    "Some of the questions you will ask yourselves throughout the notebook are:\n",
    "- How has covid changed the use of taxis in NYC?\n",
    "- What pick-up distribution do the taxis follow and what distance / duration do they take?\n",
    "- What are the areas where taxis are picked up the least? And where else do people go?\n",
    "- What are the most usual times?\n",
    "- Which days of the week and month are used the most? Possible reasons?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-helena",
   "metadata": {},
   "source": [
    "**Install and import the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b1c45c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from pyarrow) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyshp in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (2.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (1.8.5.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: descartes in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from descartes) (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (9.3.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (1.23.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib->descartes) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->descartes) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\msi\\documents\\trasladar\\yo\\software engineering\\data science & machine learning\\0. course\\project 1\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow\n",
    "! pip install pyshp\n",
    "! pip install shapely\n",
    "! pip install descartes\n",
    "! pip install pandas matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "express-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from shapely.geometry import Polygon\n",
    "from descartes.patch import PolygonPatch\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "YEARS = [2019, 2020, 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-sight",
   "metadata": {},
   "source": [
    "First of all, you need to download the data:\n",
    "\n",
    "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fantastic-footage",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32504cec874e469ea8a193ed05264461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the Trip Record Data\n",
    "for year in tqdm(YEARS):\n",
    "    if not os.path.exists(f'data/{year}'):\n",
    "        os.makedirs(f'data/{year}', exist_ok=True)\n",
    "        for month in tqdm(range(1, 13)): \n",
    "            urllib.request.urlretrieve(f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month:02d}.parquet', f'data/{year}/{month:02d}.parquet')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-values",
   "metadata": {},
   "source": [
    "## 01. Data cleaning\n",
    "\n",
    "In order to have clean and useful data, it is necessary to delete all those rows that contain corrupt information:\n",
    "- The pick-up is after the drop-off.\n",
    "- Dates are imported by months and years. Are the dates correct?\n",
    "- Traveling with zero passengers?\n",
    "- Do you travel very long or particularly short?\n",
    "- Negative payments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-collapse",
   "metadata": {},
   "source": [
    "**Data Dictionary**\n",
    "\n",
    "Only the next columns are needed:\n",
    "\n",
    "- *tpep_pickup_datetime*: The date and time when the meter was engaged.\n",
    "- *tpep_dropoff_datetime*: The date and time when the meter was disengaged. \n",
    "- *Passenger_count*: The number of passengers in the vehicle. (This is a driver-entered value)\n",
    "- *Trip_distance*: The elapsed trip distance in miles reported by the taximeter.\n",
    "- *PULocationID*: TLC Taxi Zone in which the taximeter was engaged\n",
    "- *DOLocationID*: TLC Taxi Zone in which the taximeter was disengaged\n",
    "- *Payment_type*: A numeric code signifying how the passenger paid for the trip. \n",
    "    - 1= Credit card\n",
    "    - 2= Cash\n",
    "    - 3= No charge\n",
    "    - 4= Dispute\n",
    "    - 5= Unknown\n",
    "    - 6= Voided trip\n",
    "- *Fare_amount*: The time-and-distance fare calculated by the meter.\n",
    "- *Total_amount*: The total amount charged to passengers. Does not include cash tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-bloom",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "\n",
    "- To speed up the calculations and reduce the computation time, do a uniform sampling of the data (a sample out of 1000).\n",
    "- Datetime columns are *to_datetime* series (help to search functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dependent-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(year: str, month: str):\n",
    "    \"\"\"\n",
    "    Function that reads the downloaded data and converts it to a DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    return pq.read_table(f'data/{year}/{str(month).zfill(2)}.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c291d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2019'\n",
    "month = '01'\n",
    "\n",
    "df = load_table(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67282652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20              1.0   \n",
       "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59              1.0   \n",
       "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40              3.0   \n",
       "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45              5.0   \n",
       "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33              5.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.5         1.0                  N           151           239   \n",
       "1            2.6         1.0                  N           239           246   \n",
       "2            0.0         1.0                  N           236           236   \n",
       "3            0.0         1.0                  N           193           193   \n",
       "4            0.0         2.0                  N           193           193   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          7.0    0.5      0.5        1.65           0.0   \n",
       "1             1         14.0    0.5      0.5        1.00           0.0   \n",
       "2             1          4.5    0.5      0.5        0.00           0.0   \n",
       "3             2          3.5    0.5      0.5        0.00           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge airport_fee  \n",
       "0                    0.3          9.95                   NaN        None  \n",
       "1                    0.3         16.30                   NaN        None  \n",
       "2                    0.3          5.80                   NaN        None  \n",
       "3                    0.3          7.55                   NaN        None  \n",
       "4                    0.3         55.55                   NaN        None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31705706",
   "metadata": {},
   "source": [
    "We will develop **OOP** classes to make the cleaning of the data, so we can **encapsulate** the funtionalities, and in the case we wanted, would be very easy for us to keep track of how the data is changing in each step.\n",
    "\n",
    "In each object, we have the one or more **atomical functions** (*static methods*). For those, there are simple **tests** to make sure that they are working fine.\n",
    "\n",
    "TODOs:\n",
    "- Handle NaNs & inf in columns: passenger count, ...\n",
    "- Passenger Counts filter does not work (there are 0.0s -> convert to int and then filter?). Should check that all of them are also .0, there is no half passenger\n",
    "- Assert is_unique in \n",
    "- Display map of the taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "61af7050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID',\n",
       "       'store_and_fwd_flag', 'PULocationID', 'DOLocationID',\n",
       "       'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount',\n",
       "       'tolls_amount', 'improvement_surcharge', 'total_amount',\n",
       "       'congestion_surcharge', 'airport_fee', 'days',\n",
       "       'voyage_time_outliers', 'diff', 'trip_distance_outlier',\n",
       "       'pickup_days', 'pickup_month', 'pickup_year', 'dropoff_days',\n",
       "       'dropoff_month', 'dropoff_year', 'total_amount_outlier',\n",
       "       'fare_amount_outlier'], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_proc_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a5800d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class BoundaryFilters():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_nan(\n",
    "        self,\n",
    "        column\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Remove the NaN values that we have\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = self.df[np.logical_not(np.isnan(self.df[column]))]\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_lower_bound_field(\n",
    "        self,\n",
    "        column: str, \n",
    "        value: float = 0.0,\n",
    "        convert_int: bool = False\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Filter the values which are lower than a certain value for a given column.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - column: the column for which we want to filter the values\n",
    "        - value: the value that we  want to set lower bound\n",
    "        - convert_int: whether we want to convert the variable into an integer\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe the field lower bounded\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # First we remove the NaNs, we we would not be able to make this filter\n",
    "        self.remove_nan(self, column)\n",
    "\n",
    "        if convert_int:\n",
    "            self.df[column] = self.df[column].astype(int)\n",
    "        self.df = self.df[self.df[column] > value]\n",
    "        \n",
    "        # We make the text\n",
    "        assert min(self.df[column]) > value\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    @staticmethod\n",
    "    def set_upper_bound_field(\n",
    "        self,\n",
    "        column: str,\n",
    "        value: float,\n",
    "        convert_int: bool = False\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Filter the values which are higher than a certain value for a given column.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - column: the column for which we want to filter the values\n",
    "        - value: the value that we  want to set higher bound\n",
    "        - convert_int: whether we want to convert the variable into an integer\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe the field higher bounded\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # First we remove the NaNs, we we would not be able to make this filter\n",
    "        self.remove_nan(self, column)\n",
    "        \n",
    "        if convert_int:\n",
    "            self.df[column] = self.df[column].astype(int)\n",
    "        self.df = self.df[self.df[column] < value]\n",
    "        \n",
    "        # We make the text\n",
    "        assert max(self.df[column]) <= value\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def filter_lower_bound(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Apply to a group of fields a lower bound.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with a lower bound applied to a filter\n",
    "        \n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        self.set_lower_bound_field(self, 'passenger_count', True)\n",
    "        self.set_lower_bound_field(self, 'total_amount')\n",
    "        self.set_lower_bound_field(self, 'fare_amount')\n",
    "        self.set_lower_bound_field(self, 'trip_distance')\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def filter_upper_bound(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Apply to a group of fields a higher bound.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with a higher bound applied to a filter\n",
    "        \n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "        self.set_upper_bound_field(self, 'trip_distance', 6700)\n",
    "        self.set_upper_bound_field(self, 'payment_type', 7)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def filter_positive_diff(\n",
    "        self,\n",
    "        fields: List[str] = ['tpep_dropoff_datetime', 'tpep_pickup_datetime'],\n",
    "        is_date: bool = True\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to filter for the voyages that had a duration which is > 0.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - fields: the fields for which we will make a comparison and filter them by positivity\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with only voyages that had a duration > 0\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.df['diff'] = self.df[fields[0]] - self.df[fields[1]]\n",
    "        \n",
    "        if is_date:\n",
    "            self.df['diff'] = self.df['diff'].dt.total_seconds()\n",
    "\n",
    "        # Filter by positive voyages\n",
    "        self.set_lower_bound_field(self, 'diff')\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def apply_filters(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to apply a group of filters into the dataframe.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the filters applied to it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.filter_lower_bound()\n",
    "        self.filter_upper_bound()\n",
    "        self.filter_positive_diff()\n",
    "        \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc2a9a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 < 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb1447e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:57:32</td>\n",
       "      <td>2019-01-01 01:09:32</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>141</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:24:04</td>\n",
       "      <td>2019-01-01 00:47:06</td>\n",
       "      <td>2</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>246</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:17:00</td>\n",
       "      <td>2019-01-01 00:22:39</td>\n",
       "      <td>3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:43:19</td>\n",
       "      <td>2019-01-01 00:58:09</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:08:20</td>\n",
       "      <td>2019-01-01 00:41:51</td>\n",
       "      <td>2</td>\n",
       "      <td>19.13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.71</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.3</td>\n",
       "      <td>70.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667933</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:07:31</td>\n",
       "      <td>2019-01-31 23:14:49</td>\n",
       "      <td>3</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667934</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:36:51</td>\n",
       "      <td>2019-01-31 23:46:08</td>\n",
       "      <td>3</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667935</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:55:59</td>\n",
       "      <td>2019-02-01 00:30:41</td>\n",
       "      <td>3</td>\n",
       "      <td>8.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667936</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:04:25</td>\n",
       "      <td>2019-01-31 23:17:09</td>\n",
       "      <td>2</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667939</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:31:54</td>\n",
       "      <td>2019-01-31 23:50:36</td>\n",
       "      <td>2</td>\n",
       "      <td>4.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2081360 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "9               1  2019-01-01 00:57:32   2019-01-01 01:09:32                2   \n",
       "10              1  2019-01-01 00:24:04   2019-01-01 00:47:06                2   \n",
       "27              1  2019-01-01 00:17:00   2019-01-01 00:22:39                3   \n",
       "29              1  2019-01-01 00:43:19   2019-01-01 00:58:09                2   \n",
       "33              2  2019-01-01 00:08:20   2019-01-01 00:41:51                2   \n",
       "...           ...                  ...                   ...              ...   \n",
       "7667933         2  2019-01-31 23:07:31   2019-01-31 23:14:49                3   \n",
       "7667934         2  2019-01-31 23:36:51   2019-01-31 23:46:08                3   \n",
       "7667935         2  2019-01-31 23:55:59   2019-02-01 00:30:41                3   \n",
       "7667936         2  2019-01-31 23:04:25   2019-01-31 23:17:09                2   \n",
       "7667939         2  2019-01-31 23:31:54   2019-01-31 23:50:36                2   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "9                 2.10         1.0                  N           141   \n",
       "10                2.80         1.0                  N           246   \n",
       "27                0.60         1.0                  N           161   \n",
       "29                3.00         1.0                  N           263   \n",
       "33               19.13         2.0                  N           132   \n",
       "...                ...         ...                ...           ...   \n",
       "7667933           1.14         1.0                  N           186   \n",
       "7667934           1.89         1.0                  N           100   \n",
       "7667935           8.14         1.0                  N           234   \n",
       "7667936           4.15         1.0                  N           186   \n",
       "7667939           4.28         1.0                  N           186   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "9                 234             1         10.0    0.5      0.5        1.70   \n",
       "10                162             1         15.0    0.5      0.5        3.25   \n",
       "27                229             1          5.5    0.5      0.5        1.35   \n",
       "29                107             1         12.0    0.5      0.5        2.65   \n",
       "33                238             1         52.0    0.0      0.5       11.71   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "7667933           170             1          7.0    0.5      0.5        1.66   \n",
       "7667934           113             1          8.5    0.5      0.5        1.00   \n",
       "7667935           198             1         29.5    0.5      0.5        4.00   \n",
       "7667936            13             2         14.5    0.5      0.5        0.00   \n",
       "7667939           262             1         17.0    0.5      0.5        3.66   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "9                0.00                    0.3         13.00   \n",
       "10               0.00                    0.3         19.55   \n",
       "27               0.00                    0.3          8.15   \n",
       "29               0.00                    0.3         15.95   \n",
       "33               5.76                    0.3         70.27   \n",
       "...               ...                    ...           ...   \n",
       "7667933          0.00                    0.3          9.96   \n",
       "7667934          0.00                    0.3         10.80   \n",
       "7667935          0.00                    0.3         34.80   \n",
       "7667936          0.00                    0.3         15.80   \n",
       "7667939          0.00                    0.3         21.96   \n",
       "\n",
       "         congestion_surcharge airport_fee    diff  \n",
       "9                         NaN        None   720.0  \n",
       "10                        NaN        None  1382.0  \n",
       "27                        NaN        None   339.0  \n",
       "29                        NaN        None   890.0  \n",
       "33                        NaN        None  2011.0  \n",
       "...                       ...         ...     ...  \n",
       "7667933                   0.0        None   438.0  \n",
       "7667934                   0.0        None   557.0  \n",
       "7667935                   0.0        None  2082.0  \n",
       "7667936                   0.0        None   764.0  \n",
       "7667939                   0.0        None  1122.0  \n",
       "\n",
       "[2081360 rows x 20 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoundaryFilters(df).apply_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93974769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckField():\n",
    "    def __init__(self, df, year, month):\n",
    "        self.df = df\n",
    "        self.year = str(year).strip()\n",
    "        self.month = str(month).strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def correct_field(\n",
    "        self,\n",
    "        field_name: str,\n",
    "        field_value: float,\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to check that a certain field has consistent values with its context (correct year, month, ...)\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - field_name: the field for which we want to check for consistent values\n",
    "        - field_value: the value for which the field is consistent with its context\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the field consistent to its value\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if field_name not in ['year', 'month']:\n",
    "            raise Exception('Field Name must be: [year, month]')\n",
    "            \n",
    "        self.df[field_name] = self.df[field_name].apply(lambda x: str(x))\n",
    "        self.df = self.df[self.df[field_name] == field_value]\n",
    "        \n",
    "        # And we need to make sure that this field now only has our value wanted\n",
    "        assert self.df[field_name].unique() == field_value\n",
    "\n",
    "        return self.df\n",
    "        \n",
    "    def apply_correctness_field(\n",
    "        self,\n",
    "        field: str,\n",
    "        only_year: bool = False\n",
    "    ):        \n",
    "        \n",
    "        \"\"\"\n",
    "        Function to apply correctness about the year and month values on a certain field.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - field: the field for which we want to apply correcntess on the month & year\n",
    "        - only_year: if we want to apply correctness of only year\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the field consistent to the year & month context\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Add the data needed\n",
    "        self.df['year'] = self.df[field].dt.year\n",
    "        self.df['month'] = self.df[field].dt.month\n",
    "        \n",
    "        # Simplify the data: both pickup and dropoff on the same month, year & day\n",
    "        self.correct_field(self, 'year', self.year)\n",
    "        \n",
    "        if not only_year:\n",
    "            self.correct_field(self, 'month', self.month)\n",
    "        \n",
    "        return self.df\n",
    "\n",
    "    def apply_correctness(\n",
    "        self\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Apply correcntess of the month & year on a group of fields.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the fields consistent to the year & month context\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the correctness\n",
    "        self.apply_correctness_field('tpep_pickup_datetime')\n",
    "        self.apply_correctness_field('tpep_dropoff_datetime')\n",
    "        \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b57b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class CleanData(BoundaryFilters, CheckField):\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        year: str, \n",
    "        month: str\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialization of the Clean Data object, which have two main functionalities: Limit Boundaries & Check Fields\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - df: dataframe that we want to clean\n",
    "        - year: the year in which the dataframe has data\n",
    "        - month: the month in which the dataframe has data\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = df\n",
    "        self.year = str(year).strip()\n",
    "        self.month = str(month).strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def pre_process(\n",
    "        self,\n",
    "        columns: List[str],\n",
    "        columns_filter: bool = True,\n",
    "        rows_filter: bool = True,\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Pre Process the dataframe, which means:\n",
    "        - Only consider the columns we want\n",
    "        - Dropping duplicate rows\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - columns: the columns we want to consider only in the df\n",
    "        - columns_filter: if we want to apply the filter on the columns\n",
    "        - rows_filter: if we want to apply the filter on the rows\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the filters applied to it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Filtering the columns we have in the df\n",
    "        if columns_filter:\n",
    "            self.df = self.df[columns]\n",
    "            \n",
    "        # Filtering the rows we have in the df\n",
    "        if rows_filter:\n",
    "            self.df.drop_duplicates(inplace=True, keep='first', ignore_index=True)\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample(\n",
    "        self,\n",
    "        n\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to create a sample on the dataframe.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - n: the amount we want to reduce the initial dataframe\n",
    "        \n",
    "        Returns:\n",
    "        - df: the dataframe which is only a sample of the initial one\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        previous_length = len(self.df)\n",
    "        \n",
    "        # Create the dataframe to be a fraction of the inital one\n",
    "        frac = 1/n\n",
    "        self.df = self.df.sample(frac=frac)\n",
    "        \n",
    "        # We have to make sure that the size is correct (with a certain error)\n",
    "        # TODO: Create a function to apply this assertion\n",
    "        # assert len(self.df) * n - previous_length < previous_length / n ** 1.4\n",
    "        print(len(self.df), previous_length)\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def clean_data(\n",
    "        self, \n",
    "        columns: List[str],\n",
    "        n: int = 1000\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to apply the cleaning of the data on a dataframe.\n",
    "        \n",
    "        Params:\n",
    "        - self\n",
    "        - columns: list of columns that we want only to consider in the analysis\n",
    "        - n: the amount by which we want to reduce the initial dataframe\n",
    "        \n",
    "        Returns:\n",
    "        - df: dataframe with the data in it cleaned\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample first to speed up the process (not recommended, but just for learning pursposes)\n",
    "        self.sample(self, n)\n",
    "\n",
    "        self.pre_process(self, columns)\n",
    "        self.apply_filters()\n",
    "        self.apply_correctness()\n",
    "        \n",
    "        self.df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caring-timber",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "required_data = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', \n",
    "                 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'total_amount']\n",
    "\n",
    "def clean_data(data, year, month, sampling = 1000):\n",
    "    \"\"\"\n",
    "    Function that clears the month data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using Objects we can encapsulate the functionalities we want (and we could keep track of each state of the process)\n",
    "    clean_data_instance = CleanData(data, year, month)\n",
    "    \n",
    "    clean_data_df = clean_data_instance.clean_data(\n",
    "        columns=required_data,\n",
    "        n=sampling\n",
    "    )\n",
    "    \n",
    "    return clean_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8585d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7668 7667945\n"
     ]
    }
   ],
   "source": [
    "new_df = clean_data(df, '2019', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca69e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>diff</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-17 18:56:15</td>\n",
       "      <td>2019-01-17 19:05:50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.27</td>\n",
       "      <td>164</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>11.16</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-25 22:22:08</td>\n",
       "      <td>2019-01-25 22:28:57</td>\n",
       "      <td>4</td>\n",
       "      <td>1.20</td>\n",
       "      <td>263</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.35</td>\n",
       "      <td>409.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-06 13:57:16</td>\n",
       "      <td>2019-01-06 14:07:04</td>\n",
       "      <td>6</td>\n",
       "      <td>2.29</td>\n",
       "      <td>236</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>12.36</td>\n",
       "      <td>588.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03 10:07:15</td>\n",
       "      <td>2019-01-03 10:11:04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>229.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-25 16:49:12</td>\n",
       "      <td>2019-01-25 16:55:32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2019-01-05 00:00:33</td>\n",
       "      <td>2019-01-05 00:04:23</td>\n",
       "      <td>5</td>\n",
       "      <td>1.15</td>\n",
       "      <td>229</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.84</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2019-01-14 13:42:56</td>\n",
       "      <td>2019-01-14 13:50:10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.99</td>\n",
       "      <td>143</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>434.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>2019-01-15 01:11:30</td>\n",
       "      <td>2019-01-15 01:21:55</td>\n",
       "      <td>2</td>\n",
       "      <td>5.71</td>\n",
       "      <td>48</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.30</td>\n",
       "      <td>625.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2019-01-15 09:42:29</td>\n",
       "      <td>2019-01-15 09:58:45</td>\n",
       "      <td>2</td>\n",
       "      <td>1.66</td>\n",
       "      <td>140</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15.38</td>\n",
       "      <td>976.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>2019-01-17 15:34:40</td>\n",
       "      <td>2019-01-17 15:42:53</td>\n",
       "      <td>2</td>\n",
       "      <td>1.41</td>\n",
       "      <td>68</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.96</td>\n",
       "      <td>493.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2080 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0     2019-01-17 18:56:15   2019-01-17 19:05:50                2   \n",
       "1     2019-01-25 22:22:08   2019-01-25 22:28:57                4   \n",
       "2     2019-01-06 13:57:16   2019-01-06 14:07:04                6   \n",
       "3     2019-01-03 10:07:15   2019-01-03 10:11:04                2   \n",
       "4     2019-01-25 16:49:12   2019-01-25 16:55:32                2   \n",
       "...                   ...                   ...              ...   \n",
       "2075  2019-01-05 00:00:33   2019-01-05 00:04:23                5   \n",
       "2076  2019-01-14 13:42:56   2019-01-14 13:50:10                3   \n",
       "2077  2019-01-15 01:11:30   2019-01-15 01:21:55                2   \n",
       "2078  2019-01-15 09:42:29   2019-01-15 09:58:45                2   \n",
       "2079  2019-01-17 15:34:40   2019-01-17 15:42:53                2   \n",
       "\n",
       "      trip_distance  PULocationID  DOLocationID  payment_type  fare_amount  \\\n",
       "0              1.27           164            90             1          7.5   \n",
       "1              1.20           263           239             1          7.0   \n",
       "2              2.29           236           170             1          9.5   \n",
       "3              0.80           233           233             2          5.0   \n",
       "4              0.51            90            90             1          6.0   \n",
       "...             ...           ...           ...           ...          ...   \n",
       "2075           1.15           229           141             1          5.5   \n",
       "2076           1.99           143           166             2          8.0   \n",
       "2077           5.71            48           116             1         17.0   \n",
       "2078           1.66           140           233             1         11.5   \n",
       "2079           1.41            68           249             1          7.5   \n",
       "\n",
       "      total_amount   diff  year month  \n",
       "0            11.16  575.0  2019     1  \n",
       "1            10.35  409.0  2019     1  \n",
       "2            12.36  588.0  2019     1  \n",
       "3             5.80  229.0  2019     1  \n",
       "4             9.36  380.0  2019     1  \n",
       "...            ...    ...   ...   ...  \n",
       "2075          8.84  230.0  2019     1  \n",
       "2076          8.80  434.0  2019     1  \n",
       "2077         18.30  625.0  2019     1  \n",
       "2078         15.38  976.0  2019     1  \n",
       "2079          9.96  493.0  2019     1  \n",
       "\n",
       "[2080 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6794a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpep_pickup_datetime     0\n",
       "tpep_dropoff_datetime    0\n",
       "passenger_count          0\n",
       "trip_distance            0\n",
       "PULocationID             0\n",
       "DOLocationID             0\n",
       "payment_type             0\n",
       "fare_amount              0\n",
       "total_amount             0\n",
       "diff                     0\n",
       "year                     0\n",
       "month                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After the clean data, we can check that there are no nulls\n",
    "new_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-estimate",
   "metadata": {},
   "source": [
    "In the ***post_processing*** function you can add all information you need in order to perform the necessary exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "322e21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "class PostProcessing():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    @staticmethod\n",
    "    def set_outliers_column(\n",
    "        self,\n",
    "        low: float,\n",
    "        high: float,\n",
    "        column: str,\n",
    "        output_column_name: str\n",
    "    ):\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            if row[column] < low:\n",
    "                self.df.at[idx, output_column_name] = -1\n",
    "            \n",
    "            if row[column] > high:\n",
    "                self.df.at[idx, output_column_name] = -1\n",
    "            \n",
    "            else:\n",
    "                self.df.at[idx, output_column_name] = 0\n",
    "        \n",
    "        # By default would put a float type, we can change it to int\n",
    "        self.df = self.df.astype({output_column_name: int})\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def detect_outliers_field(\n",
    "        self,\n",
    "        field: str,\n",
    "        output_column_name: str,\n",
    "        lower: float = 0.01,\n",
    "        higher: float = 0.99,\n",
    "        is_time: bool = False,\n",
    "    ):\n",
    "        \n",
    "        low, high = self.df[field].quantile([lower, higher])\n",
    "        \n",
    "         # We set the percentiles in a new oclumn\n",
    "        self.set_outliers_column(\n",
    "            self,\n",
    "            low,\n",
    "            high,\n",
    "            column=field,\n",
    "            output_column_name=output_column_name,\n",
    "        )\n",
    "                \n",
    "        # Clean the changes we have made\n",
    "\n",
    "        return self.df\n",
    "    \n",
    "    \n",
    "    def detect_outliers_diff_fields(\n",
    "        self,\n",
    "        fields: List[str] = ['tpep_dropoff_datetime', 'tpep_pickup_datetime'],\n",
    "        output_column_name: str = 'voyage_time_outliers',\n",
    "        lower: float = 0.01,\n",
    "        higher: float = 0.99,\n",
    "        is_time: bool = False,\n",
    "        keep_column: bool = False\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Detect which are the percentiles in a difference between two fields, and filter them.\n",
    "        \n",
    "        Params:\n",
    "        - fields: which are the fields that we want to make the difference\n",
    "        - output_column: the column that results of the detection of the percentile\n",
    "        - lower: the lower percentile we want to detect\n",
    "        - higher: the higher percentile we want to detect\n",
    "        - is_time: if the fields are dates or datetimes\n",
    "        - keep_column: if we want to keep the column of diff\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.df['diff'] = self.df[fields[0]] - self.df[fields[1]]\n",
    "        \n",
    "        if is_time:\n",
    "            self.df['diff'] = self.df['diff'].dt.total_seconds()\n",
    "\n",
    "        low, high = self.df['diff'].quantile([lower, higher])\n",
    "        \n",
    "        # We set the percentiles in a new oclumn\n",
    "        self.set_outliers_column(\n",
    "            self,\n",
    "            low,\n",
    "            high,\n",
    "            column='diff',\n",
    "            output_column_name=output_column_name,\n",
    "        )\n",
    "                \n",
    "        # Clean the changes we have made\n",
    "        if not keep_column:\n",
    "            self.df.drop(['diff'], axis=1, inplace=True)\n",
    "\n",
    "        return self.df\n",
    "    \n",
    "    def apply_detection_outliers(\n",
    "        self,\n",
    "        field_outliers: Dict[str, str]\n",
    "    ):\n",
    "        \n",
    "        self.detect_outliers_diff_fields(keep_column=True)\n",
    "        \n",
    "        # For the optional fields we want to compute\n",
    "        for key, value in field_outliers.items():\n",
    "            self.detect_outliers_field(key, value)\n",
    "        \n",
    "        return self.df\n",
    "        \n",
    "    \n",
    "    def get_periodical_data(\n",
    "        self,\n",
    "        column: str,\n",
    "        prefix: str\n",
    "    ):\n",
    "        \n",
    "        self.df[prefix + '_days'] = self.df[column].dt.day\n",
    "        self.df[prefix + '_month'] = self.df[column].dt.month\n",
    "        self.df[prefix + '_year'] = self.df[column].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "proprietary-leader",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_processing(data):\n",
    "    \"\"\"\n",
    "    Function to implement any type of post-processing required.\n",
    "    \"\"\"\n",
    "    \n",
    "    post_processing_instance = PostProcessing(data)\n",
    "    \n",
    "    # Get the periodical data needed\n",
    "    post_processing_instance.get_periodical_data('tpep_pickup_datetime', 'pickup')\n",
    "    post_processing_instance.get_periodical_data('tpep_dropoff_datetime', 'dropoff')\n",
    "\n",
    "    # Handle outlier information\n",
    "    field_outliers = {\n",
    "        'trip_distance': 'trip_distance_outlier',\n",
    "        'total_amount': 'total_amount_outlier',\n",
    "        'fare_amount': 'fare_amount_outlier'\n",
    "    }\n",
    "    \n",
    "    df = post_processing_instance.apply_detection_outliers(field_outliers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40d800cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_days'] = self.df[column].dt.day\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_month'] = self.df[column].dt.month\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_year'] = self.df[column].dt.year\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_days'] = self.df[column].dt.day\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_month'] = self.df[column].dt.month\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[prefix + '_year'] = self.df[column].dt.year\n",
      "C:\\Users\\Msi\\AppData\\Local\\Temp\\ipykernel_25380\\829703938.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df['diff'] = self.df[fields[0]] - self.df[fields[1]]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_proc_df = post_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dd8bc9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>diff</th>\n",
       "      <th>trip_distance_outlier</th>\n",
       "      <th>pickup_days</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>dropoff_days</th>\n",
       "      <th>dropoff_month</th>\n",
       "      <th>dropoff_year</th>\n",
       "      <th>total_amount_outlier</th>\n",
       "      <th>fare_amount_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4861329</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-21 07:10:29</td>\n",
       "      <td>2019-01-21 07:10:44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:15</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570903</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-03 20:56:06</td>\n",
       "      <td>2019-01-03 21:49:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:53:50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524641</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-31 15:56:08</td>\n",
       "      <td>2019-01-31 16:46:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:50:22</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610653</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-28 00:09:57</td>\n",
       "      <td>2019-01-28 00:10:33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:36</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66585</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 07:22:22</td>\n",
       "      <td>2019-01-01 07:22:42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080938</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-14 05:12:49</td>\n",
       "      <td>2019-01-14 05:34:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:21:38</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292617</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-23 01:35:31</td>\n",
       "      <td>2019-01-23 01:35:39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:08</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447961</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-07 18:41:03</td>\n",
       "      <td>2019-01-07 18:41:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>229</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600672</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-16 06:21:44</td>\n",
       "      <td>2019-01-16 06:22:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:35</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186829</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-22 16:44:45</td>\n",
       "      <td>2019-01-22 16:44:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:04</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "4861329         2  2019-01-21 07:10:29   2019-01-21 07:10:44              1.0   \n",
       "570903          2  2019-01-03 20:56:06   2019-01-03 21:49:56              1.0   \n",
       "7524641         1  2019-01-31 15:56:08   2019-01-31 16:46:30              1.0   \n",
       "6610653         2  2019-01-28 00:09:57   2019-01-28 00:10:33              2.0   \n",
       "66585           2  2019-01-01 07:22:22   2019-01-01 07:22:42              2.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3080938         1  2019-01-14 05:12:49   2019-01-14 05:34:27              1.0   \n",
       "5292617         2  2019-01-23 01:35:31   2019-01-23 01:35:39              1.0   \n",
       "1447961         1  2019-01-07 18:41:03   2019-01-07 18:41:03              1.0   \n",
       "3600672         2  2019-01-16 06:21:44   2019-01-16 06:22:19              1.0   \n",
       "5186829         2  2019-01-22 16:44:45   2019-01-22 16:44:49              1.0   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "4861329           0.00         1.0                  N            41   \n",
       "570903           33.25         1.0                  N           143   \n",
       "7524641          20.60         1.0                  N            87   \n",
       "6610653           0.12         1.0                  N           132   \n",
       "66585             0.00         1.0                  N           122   \n",
       "...                ...         ...                ...           ...   \n",
       "3080938          17.10         3.0                  N           143   \n",
       "5292617           0.00         5.0                  N            79   \n",
       "1447961           0.00         1.0                  N           229   \n",
       "3600672           0.00         1.0                  N           138   \n",
       "5186829           0.00         1.0                  N           264   \n",
       "\n",
       "         DOLocationID  payment_type  ...            diff  \\\n",
       "4861329            41             2  ... 0 days 00:00:15   \n",
       "570903             86             1  ... 0 days 00:53:50   \n",
       "7524641            51             1  ... 0 days 00:50:22   \n",
       "6610653           132             2  ... 0 days 00:00:36   \n",
       "66585             122             3  ... 0 days 00:00:20   \n",
       "...               ...           ...  ...             ...   \n",
       "3080938             1             1  ... 0 days 00:21:38   \n",
       "5292617            79             1  ... 0 days 00:00:08   \n",
       "1447961           264             2  ... 0 days 00:00:00   \n",
       "3600672           138             1  ... 0 days 00:00:35   \n",
       "5186829           193             1  ... 0 days 00:00:04   \n",
       "\n",
       "         trip_distance_outlier  pickup_days  pickup_month  pickup_year  \\\n",
       "4861329                      1           21             1         2019   \n",
       "570903                       1            3             1         2019   \n",
       "7524641                      1           31             1         2019   \n",
       "6610653                      0           28             1         2019   \n",
       "66585                        1            1             1         2019   \n",
       "...                        ...          ...           ...          ...   \n",
       "3080938                      0           14             1         2019   \n",
       "5292617                      1           23             1         2019   \n",
       "1447961                      1            7             1         2019   \n",
       "3600672                      1           16             1         2019   \n",
       "5186829                      1           22             1         2019   \n",
       "\n",
       "         dropoff_days  dropoff_month  dropoff_year total_amount_outlier  \\\n",
       "4861329            21              1          2019                    1   \n",
       "570903              3              1          2019                    1   \n",
       "7524641            31              1          2019                    0   \n",
       "6610653            28              1          2019                    1   \n",
       "66585               1              1          2019                    1   \n",
       "...               ...            ...           ...                  ...   \n",
       "3080938            14              1          2019                    1   \n",
       "5292617            23              1          2019                    1   \n",
       "1447961             7              1          2019                    0   \n",
       "3600672            16              1          2019                    0   \n",
       "5186829            22              1          2019                    0   \n",
       "\n",
       "         fare_amount_outlier  \n",
       "4861329                    1  \n",
       "570903                     1  \n",
       "7524641                    1  \n",
       "6610653                    1  \n",
       "66585                      1  \n",
       "...                      ...  \n",
       "3080938                    1  \n",
       "5292617                    1  \n",
       "1447961                    1  \n",
       "3600672                    1  \n",
       "5186829                    1  \n",
       "\n",
       "[112 rows x 31 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_proc_df[post_proc_df['fare_amount_outlier'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95eca4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check when one month or day in pickup != dropoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "danish-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwmUlEQVR4nO3dfXRU9Z3H8U8SMhMCDBE0CSkBoxyFKAiESqY+FDAkxehqzbZaKaYKsmBwN8lZsFREHqxQKiJqkFWQ0FNYhK66ChQygECR8GAkLYJSLbSxizOsIgzyMBmSu3/0zF1GHidmJv7g/Ton5zD3fu8v3/tNIh/vnUviLMuyBAAAYJD4lm4AAAAgUgQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxWrV0A9HS2Nio/fv3q127doqLi2vpdgAAwAWwLEtHjhxRRkaG4uPPfp3log0w+/fvV2ZmZku3AQAAmuDTTz9V586dz7r/og0w7dq1k/SPAbhcrmZbNxgMqqqqSvn5+UpMTGy2dXE6Zh0bzDk2mHNsMOfYiOac/X6/MjMz7b/Hz+aiDTCh20Yul6vZA0xycrJcLhc/HFHGrGODOccGc44N5hwbsZjz+d7+wZt4AQCAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIzTqqUbMNX1k1Yr0HDuX/X9bfLX6YUt3QIAAM2GKzAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACME1GAufLKKxUXF3faR0lJiSTpxIkTKikpUceOHdW2bVsVFRXJ5/OFrVFXV6fCwkIlJycrNTVVY8eO1cmTJ8Nq1q9fr759+8rpdKpbt26qrKz8ZmcJAAAuKhEFmO3bt+uzzz6zPzwejyTpRz/6kSSprKxMb7/9tpYtW6YNGzZo//79uueee+zjGxoaVFhYqPr6em3evFkLFy5UZWWlJk6caNfs27dPhYWFGjhwoGpra1VaWqoRI0Zo9erVzXG+AADgItAqkuIrrrgi7PX06dN19dVX6/vf/74OHz6s+fPna/HixRo0aJAkacGCBerRo4e2bNmi3NxcVVVVaffu3VqzZo3S0tLUu3dvTZ06VY899pgmTZokh8OhuXPnKisrSzNnzpQk9ejRQ5s2bdKsWbNUUFDQTKcNAABMFlGAOVV9fb1++9vfqry8XHFxcaqpqVEwGFReXp5d0717d3Xp0kXV1dXKzc1VdXW1evbsqbS0NLumoKBAo0eP1q5du9SnTx9VV1eHrRGqKS0tPWc/gUBAgUDAfu33+yVJwWBQwWCwqad5mtBaznir2daMheacQayEejaxd5Mw59hgzrHBnGMjmnO+0DWbHGDefPNNHTp0SD/72c8kSV6vVw6HQykpKWF1aWlp8nq9ds2p4SW0P7TvXDV+v1/Hjx9X69atz9jPtGnTNHny5NO2V1VVKTk5OeLzO5+p/Rqbfc1oWrlyZUu30GShW5WILuYcG8w5NphzbERjzseOHbuguiYHmPnz52vIkCHKyMho6hLNavz48SovL7df+/1+ZWZmKj8/Xy6Xq9k+TzAYlMfj0RPvxSvQGNds60bbB5PMu/0WmvXgwYOVmJjY0u1ctJhzbDDn2GDOsRHNOYfuoJxPkwLM3/72N61Zs0avv/66vS09PV319fU6dOhQ2FUYn8+n9PR0u2bbtm1ha4WeUjq15utPLvl8PrlcrrNefZEkp9Mpp9N52vbExMSofBMHGuMUaDAnwJj8gxytryHCMefYYM6xwZxjIxpzvtD1mvTvwCxYsECpqakqLCy0t+Xk5CgxMVFr1661t+3Zs0d1dXVyu92SJLfbrZ07d+rAgQN2jcfjkcvlUnZ2tl1z6hqhmtAaAAAAEQeYxsZGLViwQMXFxWrV6v8v4LRv317Dhw9XeXm53nnnHdXU1OjBBx+U2+1Wbm6uJCk/P1/Z2dkaNmyY/vjHP2r16tWaMGGCSkpK7Ksno0aN0t69ezVu3Dh99NFHmjNnjpYuXaqysrJmOmUAAGC6iG8hrVmzRnV1dXrooYdO2zdr1izFx8erqKhIgUBABQUFmjNnjr0/ISFBy5cv1+jRo+V2u9WmTRsVFxdrypQpdk1WVpZWrFihsrIyzZ49W507d9a8efN4hBoAANgiDjD5+fmyrDM/QpyUlKSKigpVVFSc9fiuXbue94mYAQMGaMeOHZG2BgAALhH8LiQAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGCfiAPM///M/+ulPf6qOHTuqdevW6tmzp9577z17v2VZmjhxojp16qTWrVsrLy9PH3/8cdgaBw8e1NChQ+VyuZSSkqLhw4frq6++Cqv505/+pFtuuUVJSUnKzMzUjBkzmniKAADgYhNRgPnyyy910003KTExUb///e+1e/duzZw5U5dddpldM2PGDD3//POaO3eutm7dqjZt2qigoEAnTpywa4YOHapdu3bJ4/Fo+fLl2rhxo0aOHGnv9/v9ys/PV9euXVVTU6Nf//rXmjRpkl5++eVmOGUAAGC6VpEU/+pXv1JmZqYWLFhgb8vKyrL/bFmWnnvuOU2YMEF33XWXJOk3v/mN0tLS9Oabb+q+++7Thx9+qFWrVmn79u3q16+fJOmFF17Q7bffrmeeeUYZGRlatGiR6uvr9eqrr8rhcOi6665TbW2tnn322bCgAwAALk0RBZi33npLBQUF+tGPfqQNGzboO9/5jh555BE9/PDDkqR9+/bJ6/UqLy/PPqZ9+/bq37+/qqurdd9996m6ulopKSl2eJGkvLw8xcfHa+vWrfrhD3+o6upq3XrrrXI4HHZNQUGBfvWrX+nLL78Mu+ITEggEFAgE7Nd+v1+SFAwGFQwGIznNcwqt5Yy3mm3NWGjOGcRKqGcTezcJc44N5hwbzDk2ojnnC10zogCzd+9evfTSSyovL9cvfvELbd++Xf/6r/8qh8Oh4uJieb1eSVJaWlrYcWlpafY+r9er1NTU8CZatVKHDh3Cak69snPqml6v94wBZtq0aZo8efJp26uqqpScnBzJaV6Qqf0am33NaFq5cmVLt9BkHo+npVu4JDDn2GDOscGcYyMacz527NgF1UUUYBobG9WvXz89/fTTkqQ+ffrogw8+0Ny5c1VcXBx5l81o/PjxKi8vt1/7/X5lZmYqPz9fLper2T5PMBiUx+PRE+/FK9AY12zrRtsHkwpauoWIhWY9ePBgJSYmtnQ7Fy3mHBvMOTaYc2xEc86hOyjnE1GA6dSpk7Kzs8O29ejRQ//1X/8lSUpPT5ck+Xw+derUya7x+Xzq3bu3XXPgwIGwNU6ePKmDBw/ax6enp8vn84XVhF6Har7O6XTK6XSetj0xMTEq38SBxjgFGswJMCb/IEfra4hwzDk2mHNsMOfYiMacL3S9iJ5Cuummm7Rnz56wbX/+85/VtWtXSf94Q296errWrl1r7/f7/dq6davcbrckye1269ChQ6qpqbFr1q1bp8bGRvXv39+u2bhxY9h9MI/Ho2uvvfaMt48AAMClJaIAU1ZWpi1btujpp5/WJ598osWLF+vll19WSUmJJCkuLk6lpaV66qmn9NZbb2nnzp164IEHlJGRobvvvlvSP67Y/OAHP9DDDz+sbdu26d1339WYMWN03333KSMjQ5J0//33y+FwaPjw4dq1a5dee+01zZ49O+wWEQAAuHRFdAvpu9/9rt544w2NHz9eU6ZMUVZWlp577jkNHTrUrhk3bpyOHj2qkSNH6tChQ7r55pu1atUqJSUl2TWLFi3SmDFjdNtttyk+Pl5FRUV6/vnn7f3t27dXVVWVSkpKlJOTo8svv1wTJ07kEWoAACApwgAjSXfccYfuuOOOs+6Pi4vTlClTNGXKlLPWdOjQQYsXLz7n5+nVq5f+8Ic/RNoeAAC4BPC7kAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTkQBZtKkSYqLiwv76N69u73/xIkTKikpUceOHdW2bVsVFRXJ5/OFrVFXV6fCwkIlJycrNTVVY8eO1cmTJ8Nq1q9fr759+8rpdKpbt26qrKxs+hkCAICLTsRXYK677jp99tln9semTZvsfWVlZXr77be1bNkybdiwQfv379c999xj729oaFBhYaHq6+u1efNmLVy4UJWVlZo4caJds2/fPhUWFmrgwIGqra1VaWmpRowYodWrV3/DUwUAABeLVhEf0KqV0tPTT9t++PBhzZ8/X4sXL9agQYMkSQsWLFCPHj20ZcsW5ebmqqqqSrt379aaNWuUlpam3r17a+rUqXrsscc0adIkORwOzZ07V1lZWZo5c6YkqUePHtq0aZNmzZqlgoKCb3i6AADgYhBxgPn444+VkZGhpKQkud1uTZs2TV26dFFNTY2CwaDy8vLs2u7du6tLly6qrq5Wbm6uqqur1bNnT6Wlpdk1BQUFGj16tHbt2qU+ffqouro6bI1QTWlp6Tn7CgQCCgQC9mu/3y9JCgaDCgaDkZ7mWYXWcsZbzbZmLDTnDGIl1LOJvZuEOccGc44N5hwb0Zzzha4ZUYDp37+/Kisrde211+qzzz7T5MmTdcstt+iDDz6Q1+uVw+FQSkpK2DFpaWnyer2SJK/XGxZeQvtD+85V4/f7dfz4cbVu3fqMvU2bNk2TJ08+bXtVVZWSk5MjOc0LMrVfY7OvGU0rV65s6RaazOPxtHQLlwTmHBvMOTaYc2xEY87Hjh27oLqIAsyQIUPsP/fq1Uv9+/dX165dtXTp0rMGi1gZP368ysvL7dd+v1+ZmZnKz8+Xy+Vqts8TDAbl8Xj0xHvxCjTGNdu60fbBJPNuv4VmPXjwYCUmJrZ0Oxct5hwbzDk2mHNsRHPOoTso5xPxLaRTpaSk6JprrtEnn3yiwYMHq76+XocOHQq7CuPz+ez3zKSnp2vbtm1ha4SeUjq15utPLvl8PrlcrnOGJKfTKafTedr2xMTEqHwTBxrjFGgwJ8CY/IMcra8hwjHn2GDOscGcYyMac77Q9b7RvwPz1Vdf6S9/+Ys6deqknJwcJSYmau3atfb+PXv2qK6uTm63W5Lkdru1c+dOHThwwK7xeDxyuVzKzs62a05dI1QTWgMAACCiAPPv//7v2rBhg/76179q8+bN+uEPf6iEhAT95Cc/Ufv27TV8+HCVl5frnXfeUU1NjR588EG53W7l5uZKkvLz85Wdna1hw4bpj3/8o1avXq0JEyaopKTEvnoyatQo7d27V+PGjdNHH32kOXPmaOnSpSorK2v+swcAAEaK6BbS3//+d/3kJz/RF198oSuuuEI333yztmzZoiuuuEKSNGvWLMXHx6uoqEiBQEAFBQWaM2eOfXxCQoKWL1+u0aNHy+12q02bNiouLtaUKVPsmqysLK1YsUJlZWWaPXu2OnfurHnz5vEINQAAsEUUYJYsWXLO/UlJSaqoqFBFRcVZa7p27XreJ2IGDBigHTt2RNIaAAC4hPC7kAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwzjcKMNOnT1dcXJxKS0vtbSdOnFBJSYk6duyotm3bqqioSD6fL+y4uro6FRYWKjk5WampqRo7dqxOnjwZVrN+/Xr17dtXTqdT3bp1U2Vl5TdpFQAAXESaHGC2b9+u//iP/1CvXr3CtpeVlentt9/WsmXLtGHDBu3fv1/33HOPvb+hoUGFhYWqr6/X5s2btXDhQlVWVmrixIl2zb59+1RYWKiBAweqtrZWpaWlGjFihFavXt3UdgEAwEWkSQHmq6++0tChQ/XKK6/osssus7cfPnxY8+fP17PPPqtBgwYpJydHCxYs0ObNm7VlyxZJUlVVlXbv3q3f/va36t27t4YMGaKpU6eqoqJC9fX1kqS5c+cqKytLM2fOVI8ePTRmzBj98z//s2bNmtUMpwwAAEzXqikHlZSUqLCwUHl5eXrqqafs7TU1NQoGg8rLy7O3de/eXV26dFF1dbVyc3NVXV2tnj17Ki0tza4pKCjQ6NGjtWvXLvXp00fV1dVha4RqTr1V9XWBQECBQMB+7ff7JUnBYFDBYLApp3lGobWc8VazrRkLzTmDWAn1bGLvJmHOscGcY4M5x0Y053yha0YcYJYsWaL3339f27dvP22f1+uVw+FQSkpK2Pa0tDR5vV675tTwEtof2neuGr/fr+PHj6t169anfe5p06Zp8uTJp22vqqpScnLyhZ/gBZrar7HZ14ymlStXtnQLTebxeFq6hUsCc44N5hwbzDk2ojHnY8eOXVBdRAHm008/1b/927/J4/EoKSmpSY1Fy/jx41VeXm6/9vv9yszMVH5+vlwuV7N9nmAwKI/Hoyfei1egMa7Z1o22DyYVtHQLEQvNevDgwUpMTGzpdi5azDk2mHNsMOfYiOacQ3dQzieiAFNTU6MDBw6ob9++9raGhgZt3LhRL774olavXq36+nodOnQo7CqMz+dTenq6JCk9PV3btm0LWzf0lNKpNV9/csnn88nlcp3x6oskOZ1OOZ3O07YnJiZG5Zs40BinQIM5AcbkH+RofQ0RjjnHBnOODeYcG9GY84WuF9GbeG+77Tbt3LlTtbW19ke/fv00dOhQ+8+JiYlau3atfcyePXtUV1cnt9stSXK73dq5c6cOHDhg13g8HrlcLmVnZ9s1p64RqgmtAQAALm0RXYFp166drr/++rBtbdq0UceOHe3tw4cPV3l5uTp06CCXy6VHH31Ubrdbubm5kqT8/HxlZ2dr2LBhmjFjhrxeryZMmKCSkhL7CsqoUaP04osvaty4cXrooYe0bt06LV26VCtWrGiOcwYAAIZr0lNI5zJr1izFx8erqKhIgUBABQUFmjNnjr0/ISFBy5cv1+jRo+V2u9WmTRsVFxdrypQpdk1WVpZWrFihsrIyzZ49W507d9a8efNUUGDe+zgAAEDz+8YBZv369WGvk5KSVFFRoYqKirMe07Vr1/M+FTNgwADt2LHjm7YHAAAuQvwuJAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYJ6IA89JLL6lXr15yuVxyuVxyu936/e9/b+8/ceKESkpK1LFjR7Vt21ZFRUXy+Xxha9TV1amwsFDJyclKTU3V2LFjdfLkybCa9evXq2/fvnI6nerWrZsqKyubfoYAAOCiE1GA6dy5s6ZPn66amhq99957GjRokO666y7t2rVLklRWVqa3335by5Yt04YNG7R//37dc8899vENDQ0qLCxUfX29Nm/erIULF6qyslITJ060a/bt26fCwkINHDhQtbW1Ki0t1YgRI7R69epmOmUAAGC6VpEU33nnnWGvf/nLX+qll17Sli1b1LlzZ82fP1+LFy/WoEGDJEkLFixQjx49tGXLFuXm5qqqqkq7d+/WmjVrlJaWpt69e2vq1Kl67LHHNGnSJDkcDs2dO1dZWVmaOXOmJKlHjx7atGmTZs2apYKCgmY6bQAAYLKIAsypGhoatGzZMh09elRut1s1NTUKBoPKy8uza7p3764uXbqourpaubm5qq6uVs+ePZWWlmbXFBQUaPTo0dq1a5f69Omj6urqsDVCNaWlpefsJxAIKBAI2K/9fr8kKRgMKhgMNvU0TxNayxlvNduasdCcM4iVUM8m9m4S5hwbzDk2mHNsRHPOF7pmxAFm586dcrvdOnHihNq2bas33nhD2dnZqq2tlcPhUEpKSlh9WlqavF6vJMnr9YaFl9D+0L5z1fj9fh0/flytW7c+Y1/Tpk3T5MmTT9teVVWl5OTkSE/zvKb2a2z2NaNp5cqVLd1Ck3k8npZu4ZLAnGODOccGc46NaMz52LFjF1QXcYC59tprVVtbq8OHD+t3v/udiouLtWHDhogbbG7jx49XeXm5/drv9yszM1P5+flyuVzN9nmCwaA8Ho+eeC9egca4Zls32j6YZN7tt9CsBw8erMTExJZu56LFnGODOccGc46NaM45dAflfCIOMA6HQ926dZMk5eTkaPv27Zo9e7buvfde1dfX69ChQ2FXYXw+n9LT0yVJ6enp2rZtW9h6oaeUTq35+pNLPp9PLpfrrFdfJMnpdMrpdJ62PTExMSrfxIHGOAUazAkwJv8gR+triHDMOTaYc2ww59iIxpwvdL1v/O/ANDY2KhAIKCcnR4mJiVq7dq29b8+ePaqrq5Pb7ZYkud1u7dy5UwcOHLBrPB6PXC6XsrOz7ZpT1wjVhNYAAACI6ArM+PHjNWTIEHXp0kVHjhzR4sWLtX79eq1evVrt27fX8OHDVV5erg4dOsjlcunRRx+V2+1Wbm6uJCk/P1/Z2dkaNmyYZsyYIa/XqwkTJqikpMS+ejJq1Ci9+OKLGjdunB566CGtW7dOS5cu1YoVK5r/7AEAgJEiCjAHDhzQAw88oM8++0zt27dXr169tHr1ag0ePFiSNGvWLMXHx6uoqEiBQEAFBQWaM2eOfXxCQoKWL1+u0aNHy+12q02bNiouLtaUKVPsmqysLK1YsUJlZWWaPXu2OnfurHnz5vEINQAAsEUUYObPn3/O/UlJSaqoqFBFRcVZa7p27XreJ2IGDBigHTt2RNIaAAC4hPC7kAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTkQBZtq0afrud7+rdu3aKTU1VXfffbf27NkTVnPixAmVlJSoY8eOatu2rYqKiuTz+cJq6urqVFhYqOTkZKWmpmrs2LE6efJkWM369evVt29fOZ1OdevWTZWVlU07QwAAcNGJKMBs2LBBJSUl2rJlizwej4LBoPLz83X06FG7pqysTG+//baWLVumDRs2aP/+/brnnnvs/Q0NDSosLFR9fb02b96shQsXqrKyUhMnTrRr9u3bp8LCQg0cOFC1tbUqLS3ViBEjtHr16mY4ZQAAYLpWkRSvWrUq7HVlZaVSU1NVU1OjW2+9VYcPH9b8+fO1ePFiDRo0SJK0YMEC9ejRQ1u2bFFubq6qqqq0e/durVmzRmlpaerdu7emTp2qxx57TJMmTZLD4dDcuXOVlZWlmTNnSpJ69OihTZs2adasWSooKGimUwcAAKaKKMB83eHDhyVJHTp0kCTV1NQoGAwqLy/Prunevbu6dOmi6upq5ebmqrq6Wj179lRaWppdU1BQoNGjR2vXrl3q06ePqqurw9YI1ZSWlp61l0AgoEAgYL/2+/2SpGAwqGAw+E1OM0xoLWe81WxrxkJzziBWQj2b2LtJmHNsMOfYYM6xEc05X+iaTQ4wjY2NKi0t1U033aTrr79ekuT1euVwOJSSkhJWm5aWJq/Xa9ecGl5C+0P7zlXj9/t1/PhxtW7d+rR+pk2bpsmTJ5+2vaqqSsnJyU07yXOY2q+x2deMppUrV7Z0C03m8XhauoVLAnOODeYcG8w5NqIx52PHjl1QXZMDTElJiT744ANt2rSpqUs0q/Hjx6u8vNx+7ff7lZmZqfz8fLlcrmb7PMFgUB6PR0+8F69AY1yzrRttH0wy79ZbaNaDBw9WYmJiS7dz0WLOscGcY4M5x0Y05xy6g3I+TQowY8aM0fLly7Vx40Z17tzZ3p6enq76+nodOnQo7CqMz+dTenq6XbNt27aw9UJPKZ1a8/Unl3w+n1wu1xmvvkiS0+mU0+k8bXtiYmJUvokDjXEKNJgTYEz+QY7W1xDhmHNsMOfYYM6xEY05X+h6ET2FZFmWxowZozfeeEPr1q1TVlZW2P6cnBwlJiZq7dq19rY9e/aorq5ObrdbkuR2u7Vz504dOHDArvF4PHK5XMrOzrZrTl0jVBNaAwAAXNoiugJTUlKixYsX67//+7/Vrl07+z0r7du3V+vWrdW+fXsNHz5c5eXl6tChg1wulx599FG53W7l5uZKkvLz85Wdna1hw4ZpxowZ8nq9mjBhgkpKSuwrKKNGjdKLL76ocePG6aGHHtK6deu0dOlSrVixoplPHwAAmCiiKzAvvfSSDh8+rAEDBqhTp072x2uvvWbXzJo1S3fccYeKiop06623Kj09Xa+//rq9PyEhQcuXL1dCQoLcbrd++tOf6oEHHtCUKVPsmqysLK1YsUIej0c33HCDZs6cqXnz5vEINQAAkBThFRjLOv+jw0lJSaqoqFBFRcVZa7p27Xrep2IGDBigHTt2RNIeAAC4RPC7kAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgnIgDzMaNG3XnnXcqIyNDcXFxevPNN8P2W5aliRMnqlOnTmrdurXy8vL08ccfh9UcPHhQQ4cOlcvlUkpKioYPH66vvvoqrOZPf/qTbrnlFiUlJSkzM1MzZsyI/OwAAMBFKeIAc/ToUd1www2qqKg44/4ZM2bo+eef19y5c7V161a1adNGBQUFOnHihF0zdOhQ7dq1Sx6PR8uXL9fGjRs1cuRIe7/f71d+fr66du2qmpoa/frXv9akSZP08ssvN+EUAQDAxaZVpAcMGTJEQ4YMOeM+y7L03HPPacKECbrrrrskSb/5zW+UlpamN998U/fdd58+/PBDrVq1Stu3b1e/fv0kSS+88IJuv/12PfPMM8rIyNCiRYtUX1+vV199VQ6HQ9ddd51qa2v17LPPhgUdAABwaWrW98Ds27dPXq9XeXl59rb27durf//+qq6uliRVV1crJSXFDi+SlJeXp/j4eG3dutWuufXWW+VwOOyagoIC7dmzR19++WVztgwAAAwU8RWYc/F6vZKktLS0sO1paWn2Pq/Xq9TU1PAmWrVShw4dwmqysrJOWyO077LLLjvtcwcCAQUCAfu13++XJAWDQQWDwW9yWmFCaznjrWZbMxaacwaxEurZxN5NwpxjgznHBnOOjWjO+ULXbNYA05KmTZumyZMnn7a9qqpKycnJzf75pvZrbPY1o2nlypUt3UKTeTyelm7hksCcY4M5xwZzjo1ozPnYsWMXVNesASY9PV2S5PP51KlTJ3u7z+dT79697ZoDBw6EHXfy5EkdPHjQPj49PV0+ny+sJvQ6VPN148ePV3l5uf3a7/crMzNT+fn5crlc3+zEThEMBuXxePTEe/EKNMY127rR9sGkgpZuIWKhWQ8ePFiJiYkt3c5FiznHBnOODeYcG9Gcc+gOyvk0a4DJyspSenq61q5dawcWv9+vrVu3avTo0ZIkt9utQ4cOqaamRjk5OZKkdevWqbGxUf3797drHn/8cQWDQXswHo9H11577RlvH0mS0+mU0+k8bXtiYmJUvokDjXEKNJgTYEz+QY7W1xDhmHNsMOfYYM6xEY05X+h6Eb+J96uvvlJtba1qa2sl/eONu7W1taqrq1NcXJxKS0v11FNP6a233tLOnTv1wAMPKCMjQ3fffbckqUePHvrBD36ghx9+WNu2bdO7776rMWPG6L777lNGRoYk6f7775fD4dDw4cO1a9cuvfbaa5o9e3bYFRYAAHDpivgKzHvvvaeBAwfar0Ohori4WJWVlRo3bpyOHj2qkSNH6tChQ7r55pu1atUqJSUl2ccsWrRIY8aM0W233ab4+HgVFRXp+eeft/e3b99eVVVVKikpUU5Oji6//HJNnDiRR6gBAICkJgSYAQMGyLLO/gROXFycpkyZoilTppy1pkOHDlq8ePE5P0+vXr30hz/8IdL2AADAJYDfhQQAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjNOqpRsAAOBSd+XPV7R0CxFxJliacWPL9sAVGAAAYBwCDAAAMM63OsBUVFToyiuvVFJSkvr3769t27a1dEsAAOBb4FsbYF577TWVl5frySef1Pvvv68bbrhBBQUFOnDgQEu3BgAAWti3NsA8++yzevjhh/Xggw8qOztbc+fOVXJysl599dWWbg0AALSwb+VTSPX19aqpqdH48ePtbfHx8crLy1N1dfUZjwkEAgoEAvbrw4cPS5IOHjyoYDDYbL0Fg0EdO3ZMrYLxamiMa7Z1o+2LL75o6RYiFpr1F198ocTExJZu56LFnGODOceGqXNudfJoS7cQkVaNlo4da4zKnI8cOSJJsizr3D0062dtJp9//rkaGhqUlpYWtj0tLU0fffTRGY+ZNm2aJk+efNr2rKysqPRomstntnQHAICLyf1RXv/IkSNq3779Wfd/KwNMU4wfP17l5eX268bGRh08eFAdO3ZUXFzzXSnx+/3KzMzUp59+KpfL1Wzr4nTMOjaYc2ww59hgzrERzTlblqUjR44oIyPjnHXfygBz+eWXKyEhQT6fL2y7z+dTenr6GY9xOp1yOp1h21JSUqLVolwuFz8cMcKsY4M5xwZzjg3mHBvRmvO5rryEfCvfxOtwOJSTk6O1a9fa2xobG7V27Vq53e4W7AwAAHwbfCuvwEhSeXm5iouL1a9fP91444167rnndPToUT344IMt3RoAAGhh39oAc++99+p///d/NXHiRHm9XvXu3VurVq067Y29seZ0OvXkk0+edrsKzY9ZxwZzjg3mHBvMOTa+DXOOs873nBIAAMC3zLfyPTAAAADnQoABAADGIcAAAADjEGAAAIBxCDBnUFFRoSuvvFJJSUnq37+/tm3bds76ZcuWqXv37kpKSlLPnj21cuXKGHVqvkhm/corr+iWW27RZZddpssuu0x5eXnn/drgHyL9ng5ZsmSJ4uLidPfdd0e3wYtEpHM+dOiQSkpK1KlTJzmdTl1zzTX89+MCRDrn5557Ttdee61at26tzMxMlZWV6cSJEzHq1kwbN27UnXfeqYyMDMXFxenNN9887zHr169X37595XQ61a1bN1VWVka3SQthlixZYjkcDuvVV1+1du3aZT388MNWSkqK5fP5zlj/7rvvWgkJCdaMGTOs3bt3WxMmTLASExOtnTt3xrhz80Q66/vvv9+qqKiwduzYYX344YfWz372M6t9+/bW3//+9xh3bpZI5xyyb98+6zvf+Y51yy23WHfddVdsmjVYpHMOBAJWv379rNtvv93atGmTtW/fPmv9+vVWbW1tjDs3S6RzXrRokeV0Oq1FixZZ+/bts1avXm116tTJKisri3HnZlm5cqX1+OOPW6+//rolyXrjjTfOWb93714rOTnZKi8vt3bv3m298MILVkJCgrVq1aqo9UiA+Zobb7zRKikpsV83NDRYGRkZ1rRp085Y/+Mf/9gqLCwM29a/f3/rX/7lX6La58Ug0ll/3cmTJ6127dpZCxcujFaLF4WmzPnkyZPW9773PWvevHlWcXExAeYCRDrnl156ybrqqqus+vr6WLV4UYh0ziUlJdagQYPCtpWXl1s33XRTVPu8mFxIgBk3bpx13XXXhW279957rYKCgqj1xS2kU9TX16umpkZ5eXn2tvj4eOXl5am6uvqMx1RXV4fVS1JBQcFZ6/EPTZn11x07dkzBYFAdOnSIVpvGa+qcp0yZotTUVA0fPjwWbRqvKXN+66235Ha7VVJSorS0NF1//fV6+umn1dDQEKu2jdOUOX/ve99TTU2NfZtp7969WrlypW6//faY9HypaIm/C7+1/xJvS/j888/V0NBw2r/2m5aWpo8++uiMx3i93jPWe73eqPV5MWjKrL/uscceU0ZGxmk/NPh/TZnzpk2bNH/+fNXW1sagw4tDU+a8d+9erVu3TkOHDtXKlSv1ySef6JFHHlEwGNSTTz4Zi7aN05Q533///fr888918803y7IsnTx5UqNGjdIvfvGLWLR8yTjb34V+v1/Hjx9X69atm/1zcgUGRpo+fbqWLFmiN954Q0lJSS3dzkXjyJEjGjZsmF555RVdfvnlLd3ORa2xsVGpqal6+eWXlZOTo3vvvVePP/645s6d29KtXVTWr1+vp59+WnPmzNH777+v119/XStWrNDUqVNbujV8Q1yBOcXll1+uhIQE+Xy+sO0+n0/p6elnPCY9PT2ievxDU2Yd8swzz2j69Olas2aNevXqFc02jRfpnP/yl7/or3/9q+688057W2NjoySpVatW2rNnj66++uroNm2gpnw/d+rUSYmJiUpISLC39ejRQ16vV/X19XI4HFHt2URNmfMTTzyhYcOGacSIEZKknj176ujRoxo5cqQef/xxxcfz//HN4Wx/F7pcrqhcfZG4AhPG4XAoJydHa9eutbc1NjZq7dq1crvdZzzG7XaH1UuSx+M5az3+oSmzlqQZM2Zo6tSpWrVqlfr16xeLVo0W6Zy7d++unTt3qra21v74p3/6Jw0cOFC1tbXKzMyMZfvGaMr380033aRPPvnEDoiS9Oc//1mdOnUivJxFU+Z87Nix00JKKDRa/CrAZtMifxdG7e3BhlqyZInldDqtyspKa/fu3dbIkSOtlJQUy+v1WpZlWcOGDbN+/vOf2/Xvvvuu1apVK+uZZ56xPvzwQ+vJJ5/kMeoLFOmsp0+fbjkcDut3v/ud9dlnn9kfR44caalTMEKkc/46nkK6MJHOua6uzmrXrp01ZswYa8+ePdby5cut1NRU66mnnmqpUzBCpHN+8sknrXbt2ln/+Z//ae3du9eqqqqyrr76auvHP/5xS52CEY4cOWLt2LHD2rFjhyXJevbZZ60dO3ZYf/vb3yzLsqyf//zn1rBhw+z60GPUY8eOtT788EOroqKCx6hbwgsvvGB16dLFcjgc1o033mht2bLF3vf973/fKi4uDqtfunSpdc0111gOh8O67rrrrBUrVsS4Y3NFMuuuXbtakk77ePLJJ2PfuGEi/Z4+FQHmwkU6582bN1v9+/e3nE6nddVVV1m//OUvrZMnT8a4a/NEMudgMGhNmjTJuvrqq62kpCQrMzPTeuSRR6wvv/wy9o0b5J133jnjf29Dsy0uLra+//3vn3ZM7969LYfDYV111VXWggULotpjnGVxDQ0AAJiF98AAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYJz/A1yyNC6r2RPtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_obj_df = post_processing(df)\n",
    "new_obj_df['voyage_time_outliers'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff1a23f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>days</th>\n",
       "      <th>voyage_time_outliers</th>\n",
       "      <th>diff</th>\n",
       "      <th>trip_distance_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4822438</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-20 21:20:14</td>\n",
       "      <td>2019-01-20 21:26:41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:06:27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575056</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-24 07:54:05</td>\n",
       "      <td>2019-01-24 08:00:09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:06:04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978652</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-21 18:43:00</td>\n",
       "      <td>2019-01-21 18:51:12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:08:12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314143</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-11 06:55:51</td>\n",
       "      <td>2019-01-11 07:15:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:20:02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152580</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-06 11:59:26</td>\n",
       "      <td>2019-01-06 12:05:35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:06:09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604934</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-16 07:50:40</td>\n",
       "      <td>2019-01-16 07:55:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>141</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:05:19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7538189</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-31 16:51:06</td>\n",
       "      <td>2019-01-31 16:55:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>249</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:04:19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581611</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-12 00:25:15</td>\n",
       "      <td>2019-01-12 00:39:09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:13:54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403024</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-07 14:40:44</td>\n",
       "      <td>2019-01-07 14:59:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:18:19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513980</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 14:15:38</td>\n",
       "      <td>2019-01-31 14:28:03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:12:25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7697 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "4822438         2  2019-01-20 21:20:14   2019-01-20 21:26:41              1.0   \n",
       "5575056         1  2019-01-24 07:54:05   2019-01-24 08:00:09              1.0   \n",
       "4978652         1  2019-01-21 18:43:00   2019-01-21 18:51:12              3.0   \n",
       "2314143         1  2019-01-11 06:55:51   2019-01-11 07:15:53              1.0   \n",
       "1152580         1  2019-01-06 11:59:26   2019-01-06 12:05:35              0.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3604934         2  2019-01-16 07:50:40   2019-01-16 07:55:59              1.0   \n",
       "7538189         1  2019-01-31 16:51:06   2019-01-31 16:55:25              1.0   \n",
       "2581611         2  2019-01-12 00:25:15   2019-01-12 00:39:09              1.0   \n",
       "1403024         1  2019-01-07 14:40:44   2019-01-07 14:59:03              1.0   \n",
       "7513980         2  2019-01-31 14:15:38   2019-01-31 14:28:03              4.0   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "4822438           0.81         1.0                  N            74   \n",
       "5575056           0.70         1.0                  N           161   \n",
       "4978652           0.90         1.0                  N           161   \n",
       "2314143           6.60         1.0                  N           162   \n",
       "1152580           1.20         1.0                  N           264   \n",
       "...                ...         ...                ...           ...   \n",
       "3604934           0.76         1.0                  N           141   \n",
       "7538189           0.90         1.0                  N           249   \n",
       "2581611           3.03         1.0                  N           161   \n",
       "1403024           2.70         1.0                  N            48   \n",
       "7513980           1.22         1.0                  N           162   \n",
       "\n",
       "         DOLocationID  payment_type  ...  tip_amount  tolls_amount  \\\n",
       "4822438            75             2  ...        0.00           0.0   \n",
       "5575056           237             1  ...        1.55           0.0   \n",
       "4978652           170             2  ...        0.00           0.0   \n",
       "2314143           231             1  ...        4.55           0.0   \n",
       "1152580           264             2  ...        0.00           0.0   \n",
       "...               ...           ...  ...         ...           ...   \n",
       "3604934           161             1  ...        1.26           0.0   \n",
       "7538189            90             1  ...        2.00           0.0   \n",
       "2581611           249             2  ...        0.00           0.0   \n",
       "1403024           107             2  ...        0.00           0.0   \n",
       "7513980           237             1  ...        2.06           0.0   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "4822438                    0.3          6.80                   NaN   \n",
       "5575056                    0.3          7.85                   0.0   \n",
       "4978652                    0.3          7.80                   0.0   \n",
       "2314143                    0.3         27.35                   NaN   \n",
       "1152580                    0.3          7.30                   NaN   \n",
       "...                        ...           ...                   ...   \n",
       "3604934                    0.3          7.56                   NaN   \n",
       "7538189                    0.3          8.80                   0.0   \n",
       "2581611                    0.3         12.80                   NaN   \n",
       "1403024                    0.3         14.30                   NaN   \n",
       "7513980                    0.3         12.36                   0.0   \n",
       "\n",
       "         airport_fee  days  voyage_time_outliers            diff  \\\n",
       "4822438         None    20                   0.0 0 days 00:06:27   \n",
       "5575056         None    24                   0.0 0 days 00:06:04   \n",
       "4978652         None    21                   0.0 0 days 00:08:12   \n",
       "2314143         None    11                   0.0 0 days 00:20:02   \n",
       "1152580         None     6                   0.0 0 days 00:06:09   \n",
       "...              ...   ...                   ...             ...   \n",
       "3604934         None    16                   0.0 0 days 00:05:19   \n",
       "7538189         None    31                   0.0 0 days 00:04:19   \n",
       "2581611         None    12                   0.0 0 days 00:13:54   \n",
       "1403024         None     7                   0.0 0 days 00:18:19   \n",
       "7513980         None    31                   0.0 0 days 00:12:25   \n",
       "\n",
       "         trip_distance_outlier  \n",
       "4822438                    0.0  \n",
       "5575056                    0.0  \n",
       "4978652                    0.0  \n",
       "2314143                    0.0  \n",
       "1152580                    0.0  \n",
       "...                        ...  \n",
       "3604934                    0.0  \n",
       "7538189                    0.0  \n",
       "2581611                    0.0  \n",
       "1403024                    0.0  \n",
       "7513980                    0.0  \n",
       "\n",
       "[7697 rows x 23 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-retreat",
   "metadata": {},
   "source": [
    "Create a new dataset that contains all the information for the years: 2019, 2020, and 2021.\n",
    "\n",
    "Remember that in order to reduce the memory required, you can take a subsample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-melbourne",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dc92395d6f4255905d51f776af73da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850ec916b8a4514a0588e4cdf90bff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7697 7696617\n",
      "7049 7049370\n",
      "7867 7866620\n",
      "7476 7475949\n",
      "7598 7598445\n",
      "6972 6971560\n",
      "6310 6310419\n",
      "6073 6073357\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([clean_data(load_table(year, month), year, month) for year in tqdm(YEARS) for month in tqdm(range(1, 13), leave = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dee972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = post_processing(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "settled-suggestion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sampling_occurence_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, PULocationID, DOLocationID, payment_type, fare_amount, total_amount, year, month, sampling_occurence_days]\n",
       "Index: []"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-interim",
   "metadata": {},
   "source": [
    "## 02. Visualizations (by years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-title",
   "metadata": {},
   "source": [
    "### Number of trips by year\n",
    "\n",
    "Can you answer the question: **Has covid increased / decreased the number of trips made by taxis?**\n",
    "\n",
    "To answer this question, create a bar figure showing the number of trips per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df, column, xlabel, ylabel, title):\n",
    "    \"\"\"\n",
    "    A function that creates a bar figure from the dataframe *df* and the content of the *column* that contains the information.\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-bachelor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bar_plot(df, 'year', 'Any', 'Number of trips', 'Number of trips by year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-marsh",
   "metadata": {},
   "source": [
    "**Question: Is this the behavior you expected? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-entertainment",
   "metadata": {},
   "source": [
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-survey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "passive-administrator",
   "metadata": {},
   "source": [
    "Now, you will visualize **how many passengers there are per taxi and per year**.\n",
    "\n",
    "Create a figure with three subplots (one per year) where can be seen the number of passengers per year.\n",
    "\n",
    "Then repeat the same chart viewing the % (use the *norm* parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def passengers_taxi_year(df, ylim, xlabel, ylabel, title, norm = False):\n",
    "    \"\"\"\n",
    "    Function that displays how many passengers there are per taxi and per year\n",
    "    \"\"\"\n",
    "    \n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-wisdom",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "passengers_taxi_year(df, (0, 60000), 'Passengers per taxi', 'Count', 'Passengers per taxi and per year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-psychology",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "passengers_taxi_year(df, (0, 0.8), 'Passengers per taxi', '%', 'Percentage of passengers per taxi and per year', norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-modeling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "developmental-glossary",
   "metadata": {},
   "source": [
    "In the previous figure, you have visualized each year separately. To make the visualization easier to interpret, combine all the information into a graph.\n",
    "\n",
    "The expected visualization has to contain three columns (different colors) for each number of passengers.\n",
    "\n",
    "Then repeat the same chart viewing the % (use the *norm* parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def passengers_taxi(df, xlabel, ylabel, norm = False):\n",
    "    \"\"\"\n",
    "    Function that displays how many passengers there are per taxi\n",
    "    \"\"\"\n",
    "        \n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-florida",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "passengers_taxi(df, 'Passengers per taxi', 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-picnic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "passengers_taxi(df, 'Passengers per taxi', '%', norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-stability",
   "metadata": {},
   "source": [
    "**Question: What impact have you seen on the data? Do you think covid had a lot of impact?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-nickname",
   "metadata": {},
   "source": [
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-rotation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continental-catalyst",
   "metadata": {},
   "source": [
    "## 03. Number of trips\n",
    "\n",
    "So far, you have seen the number of trips there have been in the years studied.\n",
    "\n",
    "Let's study what changes can be seen if you aggregate the data by hours, days of the week, week of the year, and months.\n",
    "\n",
    "\n",
    "These visualizations have to be done for the *pick-up* and *drop-off* columns. \n",
    "\n",
    "Furthermore, the information has to be split by year and represented with dashed lines, and marked with a round or cross wherever the value is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trips(df, columns, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Function that visualizes the number of trips by different data aggregations\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-chapter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_trips(df, ['pickup_month', 'dropoff_month'], title = 'Number of trips per month', xlabel = 'Month of the year', ylabel = 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-affair",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_trips(df, ['pickup_week', 'dropoff_week'], title = 'Number of trips per week of the year', xlabel = 'Week of the year', ylabel = 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "velvet-heart",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize_trips' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [157], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_trips\u001b[49m(df, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_hour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_hour\u001b[39m\u001b[38;5;124m'\u001b[39m], title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of trips per hour\u001b[39m\u001b[38;5;124m'\u001b[39m, xlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime of day\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'visualize_trips' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_trips(df, ['pickup_hour', 'dropoff_hour'], title = 'Number of trips per hour', xlabel = 'Time of day', ylabel = 'Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-monitoring",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_trips(df, ['pickup_day', 'dropoff_day'], title = 'Number of trips per day of the week', xlabel = 'Day of the week', ylabel = 'Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-facing",
   "metadata": {},
   "source": [
    "**Question: What behaviors do you see in each case? What do you think is the reason?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-animal",
   "metadata": {},
   "source": [
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sticky-chancellor",
   "metadata": {},
   "source": [
    "## 04. Distance/duration and speed relationship\n",
    "\n",
    "In the data, there is the distance traveled by taxis on each trip. Furthermore, you can extract the duration of the trips using: *tpep_dropoff_datetime* and *tpep_pickup_datetime*.\n",
    "\n",
    "Now, you will find out how covid affected the distances and durations of journeys along with the speed of taxis.\n",
    "\n",
    "Do you think the traffic density changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-associate",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "Visualize the **histograms** of distance and duration per year.\n",
    "\n",
    "You can use *plt.hist()* or *plt.bar()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_histograms(df, column, title, xlabel, ylabel, xlim):\n",
    "    \"\"\"\n",
    "    Function that creates a histogram from the information contained in the column *column* of the dataframe *df*\n",
    "    \"\"\"\n",
    "    \n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-southeast",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_histograms(df, 'trip_distance', title = 'Distance traveled per year', \n",
    "                     xlabel = 'Distance (km)', ylabel = 'Count', xlim = (-5, 80))\n",
    "\n",
    "visualize_histograms(df, 'trip_duration', title = 'Duration of trips per year', \n",
    "                     xlabel = 'Duration (h)', ylabel = 'Count', xlim = (-1, 25) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-champion",
   "metadata": {},
   "source": [
    "**QUESTIONS:**\n",
    "\n",
    "* How do you think covid affected travel distances and durations?\n",
    "\n",
    "* And the speed of taxis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-mauritius",
   "metadata": {},
   "source": [
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-expense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "related-identification",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scatter plot and correlation\n",
    "\n",
    "Create scatter plots to illustrate the relationship between trip duration and distance.\n",
    "\n",
    "It is possible that the data contain samples outside the distribution (outliers). In this case, skip this samples and display the figure again.\n",
    "\n",
    "To see if any correlation exists, it is interesting to use the *sns.regplot()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, x_value, y_value, xlabel, ylabel, remove_outliers = False):\n",
    "    \"\"\"\n",
    "    Function that displays a scatter plot given the name of the columns that contains the information\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-beatles",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_plot(df, 'trip_distance', 'trip_duration', 'Distance (km)', 'Duration (h)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-certificate",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scatter_plot(df, 'trip_distance', 'trip_duration', 'Distance (km)', 'Duration (h)', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-genius",
   "metadata": {},
   "source": [
    "**Question: Can you see any relationship? Can you calculate the correlation between the data to get more information?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-remove",
   "metadata": {},
   "source": [
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-result",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pleased-flush",
   "metadata": {},
   "source": [
    "As you did in section 3, visualize the time and distance data for the weeks and months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_per_period(df, column_data, columns, xlabel, ylabel, title):\n",
    "    \"\"\"\n",
    "    Function that show the distance / duration of trips in the time determined\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-latvia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_per_period(df, 'trip_distance', columns = ['pickup_week', 'dropoff_week'],\n",
    "                    xlabel = 'Week of the year', ylabel = 'Mean distance (km)', title = 'Distance by weeks of the year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-negative",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_per_period(df, 'trip_distance', columns = ['pickup_month', 'dropoff_month'],\n",
    "                     xlabel = 'Month of the year', ylabel = 'Mean distance (km)', title = 'Distance by months of the year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-norway",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_per_period(df, 'trip_duration', columns = ['pickup_week', 'dropoff_week'],\n",
    "                     xlabel = 'Week of the year', ylabel = 'Mean duration (h)', title = 'Duration by weeks of the year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-triple",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_per_period(df, 'trip_duration', columns = ['pickup_month', 'dropoff_month'],\n",
    "                     xlabel = 'Month of the year', ylabel = 'Mean duration (h)', title = 'Duration by months of the year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-roberts",
   "metadata": {},
   "source": [
    "**Question: Is there any strange behavior apart from covid? What can it be caused by?**\n",
    "\n",
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-contract",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "neural-warning",
   "metadata": {},
   "source": [
    "So far, you have shown the data by aggregating different information.\n",
    "\n",
    "Now, you have to visualize the data like images. For that, you will use the *plt.imshow()* function which displays images and arrays.\n",
    "\n",
    "Implement a function that displays heatmaps by year (each function display 3 heatmaps, one per year):\n",
    "\n",
    "- a heatmap showing what time of day are the longest trips during the year.\n",
    "- a heatmap showing what time of day are the longest trips during the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(df, group, column_data, xlabel, ylabel, columns = None):\n",
    "    \"\"\"\n",
    "    Function that aggregates data appropriately to display a heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-badge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap(df, ['pickup_hour', 'pickup_dayofyear'], 'trip_duration', 'Days of the year', 'Hours of the day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-protest",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap(df, ['pickup_hour', 'pickup_day'], 'trip_duration', 'Times of day', 'Days of the week', ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "actual-participation",
   "metadata": {
    "tags": []
   },
   "source": [
    "Repeat the previous heatmaps visualizing the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(df, ['pickup_hour', 'pickup_dayofyear'], 'trip_distance', 'Days of the year', 'Times of the day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-plastic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap(df, ['pickup_hour', 'pickup_day'], 'trip_distance', 'Times of the day', 'Days of the week', ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-library",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "federal-finger",
   "metadata": {},
   "source": [
    "Finally, view the average speed at different times of the day during the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-allah",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def speed_heatmap(df, group, xlabel, ylabel, columns = None):\n",
    "    \"\"\"\n",
    "    Function that aggregates data appropriately to display a speed heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-sydney",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "speed_heatmap(df, ['pickup_hour', 'pickup_day'], 'Times of the day', 'Days of the week', ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-delaware",
   "metadata": {},
   "source": [
    "**Question: Which conclusions do you obtain from the heatmaps?**\n",
    "    \n",
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-olive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "governing-segment",
   "metadata": {},
   "source": [
    "## 05. Visualize the locations of the trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-impression",
   "metadata": {},
   "source": [
    "The data only has the ID of a location, so you need to add the latitude and longitude.\n",
    "\n",
    "This information is saved in *data/geodata/taxi_zones.shp*.\n",
    "\n",
    "The next cells can be understood as a black box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_lat_lon, draw_region_map, draw_zone_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-rebecca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sf = shapefile.Reader('data/geodata/taxi_zones.shp')\n",
    "\n",
    "fields_name = [field[0] for field in sf.fields[1:]]\n",
    "shp_dic = dict(zip(fields_name, list(range(len(fields_name)))))\n",
    "attributes = sf.records()\n",
    "shp_attr = [dict(zip(fields_name, attr)) for attr in attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.DataFrame(shp_attr).join(get_lat_lon(sf, shp_dic).set_index(\"LocationID\"), on=\"LocationID\")\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-debut",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.set_title(\"Boroughs in NYC\")\n",
    "draw_region_map(ax, sf, shp_dic)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.set_title(\"Zones in NYC\")\n",
    "draw_zone_map(ax, sf, shp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-ambassador",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "chemical-portsmouth",
   "metadata": {},
   "source": [
    "Now you have two dataframes that you need to join. Use the *pd.merge* function to add the longitude and latitude to the *df* dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOUR CODE\n",
    "merge = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-cooper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "roman-verse",
   "metadata": {},
   "source": [
    "## 06. Which are the areas/zones with more pick-up and drop-off?\n",
    "\n",
    "In this section, you have to visualize the areas where taxis are most used.\n",
    "\n",
    "The first step is to sort and save in a variable the most common places in the pick-up and drop-off.\n",
    "\n",
    "The variables *top_pu* and *top_do* contains a dataframe with columns: 'year', 'PULocationID', and 'count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick-up\n",
    "# HERE YOUR CODE\n",
    "top_pu = ...\n",
    "top_pu.columns = ['year', 'PULocationID', 'count']\n",
    "\n",
    "# Drop-off\n",
    "# HERE YOUR CODE\n",
    "top_do = ...\n",
    "top_do.columns = ['year', 'DOLocationID', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-moisture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-vacation",
   "metadata": {},
   "source": [
    "Print the 5 most frequent zones per year and in each case (pick-up and drop-off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 5\n",
    "def show_top_n(df, column, df_loc, n_top = n_top):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that print the most common zones by year\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_n(top_pu, 'PULocationID', df_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_n(top_do, 'DOLocationID', df_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-universe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "plain-evanescence",
   "metadata": {},
   "source": [
    "**Let's see with a heat map which are the most common zones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in YEARS:\n",
    "    \n",
    "    PUcount = {k:v for k, v in top_do[top_do.year == year][['DOLocationID', 'count']].values}\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.set_title(f\"Zones with most pickups - {year}\")\n",
    "    draw_zone_map(ax, sf, shp_dic, heat=PUcount, text=list(PUcount.keys())[:3])\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.set_title(f\"Zones with most drop-offs - {year}\")\n",
    "    draw_zone_map(ax, sf, shp_dic, heat=PUcount, text=list(PUcount.keys())[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-universal",
   "metadata": {},
   "source": [
    "**Question: Why do you think the Manhattan area has more trips?**\n",
    "\n",
    "> ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "protective-mambo",
   "metadata": {},
   "source": [
    "## 07. Hospitals\n",
    "\n",
    "How has the travel destination changed? Are more people going to hospitals?\n",
    "\n",
    "In the next cell, there is a DataFrame with the most important hospitals in New York and their locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = [('New York’s Presbyterian Lower Manhattan Hospital, NYC, NY, USA', '40.710255', '-74.005058'),\n",
    "('Manhattan Gastroenterology, NYC, NY, USA', '40.778259', '-73.958092'),\n",
    "('Stem Cell Therapy Hospital, NYC, NY, USA', '40.601517', '-73.961067'),\n",
    "('Park Avenue Smiles, Yonkers, NYC, NY, USA', '40.945873', '-73.890671'),\n",
    "('Cosmetic Dentistry Center, NYC, NY, USA', '40.629234', '-74.026077'),\n",
    "('Envy Smile Dental Spa, Brooklyn, NYC, NY, USA', '40.607059', '-73.960144'),\n",
    "('VIVA EVE, Forest Hills, NYC, NY, USA', '40.734291', '-73.849434'),\n",
    "('Forest Hills Medical Services, Queens, NYC, NY, USA', '40.734310', '-73.849510'),\n",
    "('Professional Gynecological Services, Brooklyn, NY, NY, USA', '40.689747', '-73.982346'),\n",
    "('Manhattan Womens Health & Wellness, New York, NY, USA', '40.741997', '-73.986107'),\n",
    "('Brooklyn Abortion Clinic, Brooklyn, NY, New York, USA', '40.689743', '-73.982368'),\n",
    "('Brooklyn GYN Place, Brooklyn, NY, USA', '40.692696', '-73.993584'),\n",
    "('Americas Holistic Doctor, NYC, NY, USA', '40.742531', '-73.985489'),\n",
    "('NJS Physical Medicine & Rehabilitation, Brooklyn, NY, USA', '40.641621', '-73.956734'),\n",
    "('DHD Medical, Brooklyn New York, USA', '40.625568', '-73.918320'),\n",
    "('Workers Compensation Doctor, New York, NY, USA', '40.652225', '-74.006104'),]\n",
    "\n",
    "hospitals = pd.DataFrame(hospitals, columns = ['Place Name', 'Latitude', 'Longitude'])\n",
    "hospitals['Latitude'] = hospitals['Latitude'].astype(float)\n",
    "hospitals['Longitude'] = hospitals['Longitude'].astype(float)\n",
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-duplicate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "necessary-rhythm",
   "metadata": {},
   "source": [
    "Use the latitude and longitude of each hospital and the latitude and longitude of the zone (information in *merge* dataframe) to see the distribution of the hospitals \"on the map\".\n",
    "\n",
    "To do this, use a scatter plot. It will be better understood if the points are transparent (parameter *alpha*).\n",
    "\n",
    "Also, remember how the longitude and latitude data have to be plotted in the figure.\n",
    "\n",
    "Then repeat the same scatter plot but separated by years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_locations(merge, hospitals):\n",
    "    \"\"\"Function showing the distribution of hospitals and taxi destinations\"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_locations(merge, hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_locations_per_year(merge, hospitals):\n",
    "    \"\"\"Function showing the distribution of hospitals and taxi destinations per year\"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_locations_per_year(merge, hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-skirt",
   "metadata": {},
   "source": [
    "**Question: Do you see any behavior?**\n",
    "\n",
    ">ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-sapphire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tired-species",
   "metadata": {},
   "source": [
    "To find out how trips to hospitals have changed, you need to detect in which zone is each hospital.\n",
    "\n",
    "To do it, you need to calculate the distances between the hospitals and the zones. \n",
    "\n",
    "Do not calculate the distance point-to-point, but matrix-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals_loc = hospitals[['Longitude', 'Latitude']].values\n",
    "loc = df_loc[['longitude', 'latitude']].values\n",
    "\n",
    "# HERE YOUR CODE\n",
    "dist = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances as an image\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-cross",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "residential-swiss",
   "metadata": {},
   "source": [
    "Find a way to locate the nearest sector based on distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOUR CODE\n",
    "hospitals_locations = ...\n",
    "hospitals['LocationID'] = hospitals_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hourly-beads",
   "metadata": {},
   "source": [
    "Now that you know the zone of each hospital, visualize how many trips are related to them.\n",
    "\n",
    "You will assume that all trips in the zone go to the hospital.\n",
    "\n",
    "Make a single figure with two bar plots showing the number of trips for each year and the % of total trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trips_hospitals(df, hospitals_locations):\n",
    "    \"\"\"\n",
    "    Function that displays a single figure with two bar plots showing the number of trips for each year and the % of total trips.\n",
    "    \"\"\"\n",
    "    # HERE YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_hospitals(df, hospitals_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-antibody",
   "metadata": {},
   "source": [
    "## 08. Curiosity killed the cat\n",
    "\n",
    "In the **first part** you must view and comment on the examples you have removed, such as very long distances, very short distances...\n",
    "\n",
    "In the **second part** you are free to choose and make visualizations that bring you extra information that has not been seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-escape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "excellent-halloween",
   "metadata": {},
   "source": [
    "## 09. Report\n",
    "\n",
    "Based on the data exploration you have done throughout this notebook, make a short report summarizing and justifying all the changes that have arisen due to covid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-inclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
