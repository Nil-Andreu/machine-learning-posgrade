{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88dc9fc2",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25afcda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import typing\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e438e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a370b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['Gener', 'Febrer', 'Marc', 'Abril', 'Maig', 'Juny', 'Juliol', 'Agost', 'Setembre', 'Octubre', 'Novembre', 'Desembre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca4eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./bicing', exist_ok=True)\n",
    "\n",
    "if not len(os.listdir('./bicing')):\n",
    "    i2m = list(zip(range(1,13), months))\n",
    "    for year in [2023, 2022, 2021, 2020, 2019]:\n",
    "        for month, month_name in i2m:        \n",
    "            os.system(f\"wget 'https://opendata-ajuntament.barcelona.cat/resources/bcn/BicingBCN/{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z'\")\n",
    "            os.system(f\"7z x '{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z'\")\n",
    "            os.system(f\"mv '{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.csv' './data' \")\n",
    "            os.system(f\"rm './data/{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e32984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc86167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(miliseconds: int):\n",
    "    return datetime.fromtimestamp(miliseconds)\n",
    "\n",
    "def create_date_df(df: pd.DataFrame):\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df['last_reported'].apply(lambda x: get_datetime(x))\n",
    "    )\n",
    "    \n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day'] = df['date'].dt.day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a97cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_time(row):\n",
    "    return datetime(\n",
    "        int(row['year']),\n",
    "        int(row['month']),\n",
    "        int(row['day']),\n",
    "        int(row['hour'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9c7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_df(new_df: pd.DataFrame):\n",
    "    # Unique values\n",
    "    new_df = new_df.drop_duplicates()\n",
    "    new_df = new_df.dropna(subset=['last_reported', 'last_updated'], axis=0)\n",
    "    new_df = new_df.sort_values('last_reported', ascending=True)\n",
    "    \n",
    "    # Convert some categorical into numerical\n",
    "    new_df.status = np.where(new_df.status == 'IN_SERVICE', 1, 0)\n",
    "    new_df.is_charging_station = np.where(new_df.is_charging_station, 1, 0)\n",
    "    \n",
    "    # Create the dates from timestamp and group statistics\n",
    "    new_df = create_date_df(new_df)\n",
    "    new_df = new_df\\\n",
    "        .groupby(['station_id', 'year', 'month', 'day', 'hour'])\\\n",
    "        .mean(numeric_only=True)\\\n",
    "        .reset_index()\n",
    "    \n",
    "    # Creation of the dates\n",
    "    new_df['date_time'] = new_df.apply(lambda row: create_date_time(row), axis=1)\n",
    "    new_df['date'] = new_df.date_time.dt.date\n",
    "    \n",
    "    # Create percentage of docks availability\n",
    "    new_df['percentage_docks_available'] = new_df['num_bikes_available'] / new_df['num_docks_available']\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4eeb922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [53:24<00:00, 64.09s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_df_processed(file_name_csv: str = 'df_processed.csv'):\n",
    "    if os.path.exists(file_name_csv):\n",
    "        return df = pd.read_csv(file_name_csv)\n",
    "        \n",
    "    for csv in tqdm(os.listdir('./bicing')):\n",
    "        new_df = pd.read_csv('./bicing/' + csv)\n",
    "        new_df = process_new_df(new_df)\n",
    "\n",
    "        # Filter out incorrect dates\n",
    "        year, month, *_ = csv.split('_')\n",
    "        year, month = int(year), int(month)\n",
    "        new_df = new_df[(new_df.year == year) & (new_df.month == month)]\n",
    "\n",
    "        df = pd.concat(\n",
    "            [df, new_df], \n",
    "            axis=0\n",
    "        )\n",
    "    \n",
    "    df.to_csv(file_name_csv, index=False, header=True)\n",
    "    return df\n",
    "\n",
    "df = get_df_processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc800ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN: Assume that the NaN in traffic is 0\n",
    "df.traffic = df.traffic.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a9f25ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16368488, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc6eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_bikes_available_types.mechanical</th>\n",
       "      <th>num_bikes_available_types.ebike</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>is_renting</th>\n",
       "      <th>is_returning</th>\n",
       "      <th>last_reported</th>\n",
       "      <th>is_charging_station</th>\n",
       "      <th>status</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>ttl</th>\n",
       "      <th>date_time</th>\n",
       "      <th>date</th>\n",
       "      <th>percentage_docks_available</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.727273</td>\n",
       "      <td>7.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.272727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590964e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590964e+09</td>\n",
       "      <td>17.363636</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.213033</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.076923</td>\n",
       "      <td>8.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590968e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590968e+09</td>\n",
       "      <td>15.461538</td>\n",
       "      <td>2020-06-01 01:00:00</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590971e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590972e+09</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>2020-06-01 02:00:00</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.213793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590975e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590975e+09</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>2020-06-01 03:00:00</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590979e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.590979e+09</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>2020-06-01 04:00:00</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  year  month  day  hour  num_bikes_available  \\\n",
       "1           1  2020      6    1     0             7.727273   \n",
       "2           1  2020      6    1     1             8.076923   \n",
       "3           1  2020      6    1     2             7.750000   \n",
       "4           1  2020      6    1     3             8.000000   \n",
       "5           1  2020      6    1     4             8.000000   \n",
       "\n",
       "   num_bikes_available_types.mechanical  num_bikes_available_types.ebike  \\\n",
       "1                              7.727273                              0.0   \n",
       "2                              8.076923                              0.0   \n",
       "3                              7.750000                              0.0   \n",
       "4                              8.000000                              0.0   \n",
       "5                              8.000000                              0.0   \n",
       "\n",
       "   num_docks_available  is_installed  is_renting  is_returning  last_reported  \\\n",
       "1            36.272727           1.0         1.0           1.0   1.590964e+09   \n",
       "2            35.923077           1.0         1.0           1.0   1.590968e+09   \n",
       "3            36.250000           1.0         1.0           1.0   1.590971e+09   \n",
       "4            36.000000           1.0         1.0           1.0   1.590975e+09   \n",
       "5            36.000000           1.0         1.0           1.0   1.590979e+09   \n",
       "\n",
       "   is_charging_station  status  last_updated        ttl           date_time  \\\n",
       "1                  1.0     1.0  1.590964e+09  17.363636 2020-06-01 00:00:00   \n",
       "2                  1.0     1.0  1.590968e+09  15.461538 2020-06-01 01:00:00   \n",
       "3                  1.0     1.0  1.590972e+09  14.083333 2020-06-01 02:00:00   \n",
       "4                  1.0     1.0  1.590975e+09  14.250000 2020-06-01 03:00:00   \n",
       "5                  1.0     1.0  1.590979e+09  19.250000 2020-06-01 04:00:00   \n",
       "\n",
       "         date  percentage_docks_available  traffic  \n",
       "1  2020-06-01                    0.213033      0.0  \n",
       "2  2020-06-01                    0.224839      0.0  \n",
       "3  2020-06-01                    0.213793      0.0  \n",
       "4  2020-06-01                    0.222222      0.0  \n",
       "5  2020-06-01                    0.222222      0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a38712",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Checkpoint\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df.to_csv('df_processed.csv', index=False, header=True)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_processed.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1037\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1158\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1434\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1430\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1431\u001b[0m     )\n\u001b[0;32m-> 1434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1437\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf4c81",
   "metadata": {},
   "source": [
    "### Add station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b61d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_json(\n",
    "    url: str = 'https://opendata-ajuntament.barcelona.cat/data/dataset/bd2462df-6e1e-4e37-8205-a4b8e7313b84/resource/e5adca8d-98bf-42c3-9b9c-364ef0a80494/download'\n",
    "):\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b28342",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_json = get_station_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(station_json['data']['stations'])\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fields are not going to be used\n",
    "station_drop_fields = [\n",
    "    'physical_configuration',          # unique value: ELECTRICBIKESTATION\n",
    "    '_ride_code_support',              # unique value: all True\n",
    "    'nearby_distance',                 # unique value: 1000\n",
    "    'name', 'address', 'post_code',    # too specific to each of the stations\n",
    "    'is_charging_station',             # already in the main df\n",
    "    'rental_uris', 'cross_street',     # vast majority are none\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = station_df.drop(station_drop_fields, axis=1)\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, station_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f465221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7af462",
   "metadata": {},
   "source": [
    "### Add Weather information\n",
    "\n",
    "Add information relative to the wather ([source](https://www.visualcrossing.com/weather/weather-data-services#))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27198904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start date: ', df['date'].min())\n",
    "print('End date: ', df['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_api_extraction(url: str) -> pd.DataFrame:\n",
    "    response = requests.get(url)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    weather_df = pd.json_normalize(response_json['days'])\n",
    "    \n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_df_drop_columns(\n",
    "    weather_df: pd.DataFrame, \n",
    "    columns_to_drop: typing.List[str] = [\n",
    "        'datetimeEpoch', \n",
    "        'tzoffset', \n",
    "        'source',\n",
    "        'name',                     # all barcelona\n",
    "        'stations',                 # which stations tracked that weather\n",
    "        'severerisk'                # all nulls\n",
    "        'precipprob',               # 100 if it rains, 0 otherwise. Doesn't add new info\n",
    "        'preciptype',               # 'rain' if it rains, 'snow' if it snows. Doesn't add new info\n",
    "        'sunrise', 'sunset',        # simplify variables, too specific\n",
    "        'description',              # simplify variables, too specific\n",
    "        'sunrise',                  # simplify variables, too specific\n",
    "        'sunset',                   # simplify variables, too specific\n",
    "        'moonphase',                # simplify variables, too specific\n",
    "        'sealevelpressure',         # simplify variables, too specific\n",
    "    ]\n",
    "):\n",
    "    \n",
    "    return weather_df.drop(columns_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_df(weather_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    weather_df.datetime = pd.to_datetime(weather_df.datetime)\n",
    "    weather_df['date'] = weather_df.datetime.dt.date\n",
    "    \n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34df108",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./weather', exist_ok=True)\n",
    "\n",
    "if not len(os.listdir('./weather')):\n",
    "    weather_url1 = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/barcelona/2019-03-28/2021-11-30?unitGroup=metric&include=days&key=4T9KXABWNUV92K2WTZMA7JXZ3&contentType=json'\n",
    "    weather_df1 = weather_api_extraction(weather_url1)\n",
    "    weather_df1.to_csv('./weather/weather_2019_03_28_to_2021_11_30.csv', index=False, header=True)\n",
    "    \n",
    "    weather_url2 = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/barcelona/2021-12-01/2023-04-30?unitGroup=metric&include=days&key=6NT6N8CRPMNTAEE2FH2EQZ98U&contentType=json'\n",
    "    weather_df2 = weather_api_extraction(weather_url2)\n",
    "    weather_df2.to_csv('./weather/weather_2021_12_01_to_2023_04_30.csv', index=False, header=True)\n",
    "\n",
    "else:\n",
    "    weather_df1 = pd.read_csv('./weather/weather_2019_03_28_to_2021_11_30.csv')\n",
    "    weather_df2 = pd.read_csv('./weather/weather_2021_12_01_to_2023_04_30.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd\\\n",
    "    .concat([weather_df1, weather_df2], axis=0)\\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df_drop_columns(weather_df)\n",
    "weather_df = process_weather_df(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d376b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae531d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fae44",
   "metadata": {},
   "source": [
    "### Add Covid Information\n",
    "\n",
    "The daily covid cases that there were in Barcelona ([source](https://www.amb.cat/en/web/area-metropolitana/dades-obertes/cataleg/detall/-/dataset/covid-19-positive-cases/9147624/11692))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covid_json(\n",
    "    url: str = \"https://opendata-ajuntament.barcelona.cat/data/api/action/datastore_search_sql?sql=SELECT%20*%20from%20%22f627ac0a-d05f-416d-9773-eeb464a3fc44%22%20WHERE%20%22Nom_Indicador%22%20LIKE%20%27Casos%20de%20COVID-19%20a%20Barcelona%20(diari)%27\"\n",
    "):\n",
    "    \n",
    "    res_covid = requests.get(url)\n",
    "    return res_covid.json()['result']['records']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_json = get_covid_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d47fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = pd.DataFrame(covid_json)\n",
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8337271",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_df[['Data_Indicador', 'Valor']]\n",
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date'] = pd.to_datetime(covid_df.Data_Indicador).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_df\\\n",
    "    .drop('Data_Indicador', axis=1)\\\n",
    "    .rename(columns={'Valor': 'covid_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df, \n",
    "    covid_df, \n",
    "    how='left', \n",
    "    left_on='date', \n",
    "    right_on='date'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351a89a",
   "metadata": {},
   "source": [
    "We only have NaN values afterwards (not previous to the start of Covid).\n",
    "\n",
    "For those NaN, we will replace them by a percentile that is at the bottom (still not 0, as there are cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.covid_cases = df.covid_cases.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98611414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.covid_cases.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.covid_cases.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4286ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_percentile(\n",
    "    df: pd.DataFrame, \n",
    "    column: str, \n",
    "    percentile: float = 0.03,\n",
    "    logging: bool = True\n",
    "):\n",
    "    \n",
    "    quantile_value = df[column].quantile(percentile)\n",
    "    \n",
    "    if logging:\n",
    "        print(f'Percentile {percentile} value is: ', quantile_value)\n",
    "        \n",
    "    df[column] = df[column].fillna(quantile_value)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986782c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_with_percentile(df, 'covid_cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2da3d7",
   "metadata": {},
   "source": [
    "We could add also information about in which dates the people where closed into their homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "confinment_start = '2020-03-14'\n",
    "confinment_date_start = datetime.strptime(confinment_start, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "confinment_end = '2020-06-21'\n",
    "confinment_date_end = datetime.strptime(confinment_start, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_non_confinment = df[\n",
    "    (df['date'] < confinment_date_start) |\n",
    "    (df['date'] > confinment_date_end)\n",
    "].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd910bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[index_non_confinment, 'confinment'] = 0\n",
    "df['confinment'] = df['confinment'].fillna(1)\n",
    "df['confinment'] = df['confinment'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2982fdf",
   "metadata": {},
   "source": [
    "### Datetime Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would need to get the dummies for them\n",
    "date_time_fields = ['day_info', 'hour_info', 'month_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f67d39",
   "metadata": {},
   "source": [
    "Related to the **day** (weekend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0eb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_info(date_time):\n",
    "    return 'weekend' if date_time.weekday() in [5, 6] else 'weekday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b081a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_info'] = df.date_time.apply(lambda x: get_day_info(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfe666",
   "metadata": {},
   "source": [
    "Related to the **hour** (which time of day it was)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour_info(date_time):\n",
    "    if date_time.hour in range(5):\n",
    "        return 'late_night'\n",
    "\n",
    "    elif date_time.hour in range(5, 9):\n",
    "        return 'early_morning'\n",
    "\n",
    "    elif date_time.hour in range(9, 13):\n",
    "        return 'morning'\n",
    "    \n",
    "    elif date_time.hour in range(13, 17):\n",
    "        return 'noon'\n",
    "    \n",
    "    elif date_time.hour in range(17, 21):\n",
    "        return 'eve'\n",
    "    \n",
    "    return 'night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adf87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_info'] = df.date_time.apply(lambda x: get_hour_info(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350cce2",
   "metadata": {},
   "source": [
    "Related to the **month** (season)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_info(date):\n",
    "    if date.month in (3, 4, 5):\n",
    "        return 'spring'\n",
    "    \n",
    "    elif date.month in (6, 7, 8):\n",
    "        return 'summer'\n",
    "    \n",
    "    elif date.month in (9, 10, 11):\n",
    "        return 'autumn'\n",
    "    \n",
    "    return 'winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_info'] = df.date_time.apply(lambda x: get_month_info(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac91b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c1820",
   "metadata": {},
   "source": [
    "### Data Shifting\n",
    "\n",
    "We need to create a shift of the availability in the previous availabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb624ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['station_id', 'date_time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484eb356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ace686",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in tqdm(df.station_id.unique()):\n",
    "    station_df = df[df.station_id == station_id]\n",
    "    station_df['ctx-4'] = station_df.percentage_docks_available.shift(4)\n",
    "    station_df['ctx-3'] = station_df.percentage_docks_available.shift(3)\n",
    "    station_df['ctx-2'] = station_df.percentage_docks_available.shift(2)\n",
    "    station_df['ctx-1'] = station_df.percentage_docks_available.shift(1)\n",
    "    \n",
    "    df_shifted = pd.concat([station_df, df_shifted], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c312652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2dac2",
   "metadata": {},
   "source": [
    "### Train / Val / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6afb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_shifted[df_shifted.year != 2023]\n",
    "test_df = df_shifted[df_shifted.year == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac323983",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train size: ', train_df.shape[0])\n",
    "print('Test size: ', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e67302",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = test_df[test_df.month <= 3]\n",
    "test_df = test_df[test_df.month > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff997945",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
